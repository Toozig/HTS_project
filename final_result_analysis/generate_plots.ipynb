{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dsi/toozig/Deep-learning-RNA-binding/utils\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsi/toozig/.virtualenvs/deepBindEnv/lib/python3.9/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd '..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = '/home/dsi/toozig/Deep-learning-RNA-binding/data/final/model_eval'\n",
    "\n",
    "train_color = '#7CB342'\n",
    "# use purple pastel color\n",
    "test_color = '#616161'\n",
    "# test_color = '#FFAB40'\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f'{result_path}/{f}' for f in os.listdir(result_path) if f.endswith('.json')]\n",
    "\n",
    "test_evals = {}\n",
    "train_evals = {}\n",
    "\n",
    "for f in files:\n",
    "    with open(f, 'r') as file:\n",
    "        prot = f.split('/')[-1].split('_')[0]\n",
    "        if int(prot.split('P')[-1]) < 39:\n",
    "            train_evals[prot] = json.load(file)\n",
    "        else:\n",
    "            test_evals[prot] = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RBP24': {'test_loss': 0.08089615404605865,\n",
       "  'test_pearson': 0.6832637190818787,\n",
       "  'val_loss': [0.08317157626152039,\n",
       "   0.08241984993219376,\n",
       "   0.08193130046129227,\n",
       "   0.08119256049394608,\n",
       "   0.08293337374925613,\n",
       "   0.0812111496925354,\n",
       "   0.08114679902791977,\n",
       "   0.08080604672431946,\n",
       "   0.08138562738895416,\n",
       "   0.08040791004896164,\n",
       "   0.08258187025785446,\n",
       "   0.08136650174856186,\n",
       "   0.0813799500465393],\n",
       "  'val_pearson': [0.6751118898391724,\n",
       "   0.6835731863975525,\n",
       "   0.6848306655883789,\n",
       "   0.685966968536377,\n",
       "   0.6843729019165039,\n",
       "   0.684748649597168,\n",
       "   0.6847829818725586,\n",
       "   0.6862730979919434,\n",
       "   0.6848368644714355,\n",
       "   0.688266932964325,\n",
       "   0.6856490969657898,\n",
       "   0.6864133477210999,\n",
       "   0.6874542832374573],\n",
       "  'train_loss': [0.088261179625988,\n",
       "   0.08312206715345383,\n",
       "   0.08211871981620789,\n",
       "   0.08173932135105133,\n",
       "   0.08157342672348022,\n",
       "   0.08160118013620377,\n",
       "   0.08141207695007324,\n",
       "   0.08117301017045975,\n",
       "   0.0811241939663887,\n",
       "   0.0810522735118866,\n",
       "   0.08097200840711594,\n",
       "   0.08100549876689911,\n",
       "   0.08089882135391235],\n",
       "  'train_pearson': [0.6576274037361145,\n",
       "   0.6793257594108582,\n",
       "   0.6838172674179077,\n",
       "   0.6854066848754883,\n",
       "   0.6863070130348206,\n",
       "   0.6868412494659424,\n",
       "   0.6874854564666748,\n",
       "   0.6880630850791931,\n",
       "   0.6885907649993896,\n",
       "   0.6888324618339539,\n",
       "   0.6890060305595398,\n",
       "   0.6888905167579651,\n",
       "   0.6890208125114441]},\n",
       " 'RBP31': {'test_loss': 0.07962143421173096,\n",
       "  'test_pearson': 0.5043666362762451,\n",
       "  'val_loss': [0.0816999301314354,\n",
       "   0.08040738105773926,\n",
       "   0.08017322421073914,\n",
       "   0.08100143074989319,\n",
       "   0.08058805018663406,\n",
       "   0.07966804504394531,\n",
       "   0.08138211071491241,\n",
       "   0.08059684187173843,\n",
       "   0.07987185567617416],\n",
       "  'val_pearson': [0.49744486808776855,\n",
       "   0.5056229829788208,\n",
       "   0.5063547492027283,\n",
       "   0.5098357796669006,\n",
       "   0.5108951926231384,\n",
       "   0.5111981630325317,\n",
       "   0.5091492533683777,\n",
       "   0.5079281330108643,\n",
       "   0.5101898908615112],\n",
       "  'train_loss': [0.08687647432088852,\n",
       "   0.0811508372426033,\n",
       "   0.08061888813972473,\n",
       "   0.08033175021409988,\n",
       "   0.08016400784254074,\n",
       "   0.0800725594162941,\n",
       "   0.07992754876613617,\n",
       "   0.07981187105178833,\n",
       "   0.07975286990404129],\n",
       "  'train_pearson': [0.4720739424228668,\n",
       "   0.5019441843032837,\n",
       "   0.5058638453483582,\n",
       "   0.507787823677063,\n",
       "   0.5090113878250122,\n",
       "   0.5102007389068604,\n",
       "   0.5114094614982605,\n",
       "   0.5120881199836731,\n",
       "   0.5130082368850708]},\n",
       " 'RBP29': {'test_loss': 0.12028158456087112,\n",
       "  'test_pearson': 0.2486068606376648,\n",
       "  'val_loss': [0.12158841639757156,\n",
       "   0.12072927504777908,\n",
       "   0.12028595060110092,\n",
       "   0.12037944048643112,\n",
       "   0.11999467760324478,\n",
       "   0.12025734037160873,\n",
       "   0.12030851095914841,\n",
       "   0.12147565186023712],\n",
       "  'val_pearson': [0.232627734541893,\n",
       "   0.2560873031616211,\n",
       "   0.2562190592288971,\n",
       "   0.2549457848072052,\n",
       "   0.2583306133747101,\n",
       "   0.25425592064857483,\n",
       "   0.25665754079818726,\n",
       "   0.25692686438560486],\n",
       "  'train_loss': [0.12633556127548218,\n",
       "   0.1209697350859642,\n",
       "   0.12039008736610413,\n",
       "   0.12036372721195221,\n",
       "   0.12034676969051361,\n",
       "   0.12029191851615906,\n",
       "   0.12024573236703873,\n",
       "   0.1201845183968544],\n",
       "  'train_pearson': [0.2202281802892685,\n",
       "   0.25056785345077515,\n",
       "   0.257625937461853,\n",
       "   0.2581092119216919,\n",
       "   0.257904052734375,\n",
       "   0.25878164172172546,\n",
       "   0.259570837020874,\n",
       "   0.26008546352386475]},\n",
       " 'RBP35': {'test_loss': 0.11677354574203491,\n",
       "  'test_pearson': 0.19548960030078888,\n",
       "  'val_loss': [0.11722345650196075,\n",
       "   0.11662062257528305,\n",
       "   0.11665951460599899,\n",
       "   0.11697469651699066,\n",
       "   0.11667178571224213],\n",
       "  'val_pearson': [0.2046707719564438,\n",
       "   0.20325545966625214,\n",
       "   0.2042185366153717,\n",
       "   0.2030118703842163,\n",
       "   0.20374096930027008],\n",
       "  'train_loss': [0.11899714916944504,\n",
       "   0.1168273314833641,\n",
       "   0.11679612100124359,\n",
       "   0.11678339540958405,\n",
       "   0.11677839607000351],\n",
       "  'train_pearson': [nan,\n",
       "   0.2036081999540329,\n",
       "   0.20372171700000763,\n",
       "   0.20398758351802826,\n",
       "   0.2040649652481079]},\n",
       " 'RBP22': {'test_loss': 0.101685531437397,\n",
       "  'test_pearson': 0.4085964858531952,\n",
       "  'val_loss': [0.10299437493085861,\n",
       "   0.10273316502571106,\n",
       "   0.10196276754140854,\n",
       "   0.10194384306669235,\n",
       "   0.10199791938066483,\n",
       "   0.10193951427936554,\n",
       "   0.10172786563634872,\n",
       "   0.10187742859125137,\n",
       "   0.10179942101240158,\n",
       "   0.10169833153486252,\n",
       "   0.10165581107139587,\n",
       "   0.10180298238992691,\n",
       "   0.10216841101646423,\n",
       "   0.10193102061748505],\n",
       "  'val_pearson': [0.3984992504119873,\n",
       "   0.40118277072906494,\n",
       "   0.4088740646839142,\n",
       "   0.40971869230270386,\n",
       "   0.410365492105484,\n",
       "   0.41067132353782654,\n",
       "   0.41088542342185974,\n",
       "   0.4109882116317749,\n",
       "   0.41168755292892456,\n",
       "   0.41132888197898865,\n",
       "   0.41203057765960693,\n",
       "   0.41049882769584656,\n",
       "   0.4104776680469513,\n",
       "   0.41014495491981506],\n",
       "  'train_loss': [0.11003096401691437,\n",
       "   0.10287018865346909,\n",
       "   0.10244255512952805,\n",
       "   0.10194392502307892,\n",
       "   0.10182216763496399,\n",
       "   0.10172530263662338,\n",
       "   0.10177541524171829,\n",
       "   0.10173530876636505,\n",
       "   0.10171707719564438,\n",
       "   0.10165977478027344,\n",
       "   0.10163348913192749,\n",
       "   0.10163117200136185,\n",
       "   0.10166370868682861,\n",
       "   0.10162008553743362],\n",
       "  'train_pearson': [0.3928428888320923,\n",
       "   0.4050336480140686,\n",
       "   0.4091419577598572,\n",
       "   0.41341012716293335,\n",
       "   0.4144830107688904,\n",
       "   0.4146682620048523,\n",
       "   0.4148578345775604,\n",
       "   0.4151895344257355,\n",
       "   0.41540512442588806,\n",
       "   0.41584038734436035,\n",
       "   0.4157973527908325,\n",
       "   0.4159430265426636,\n",
       "   0.4161185622215271,\n",
       "   0.4159928560256958]},\n",
       " 'RBP7': {'test_loss': 0.08339732885360718,\n",
       "  'test_pearson': 0.3805306851863861,\n",
       "  'val_loss': [0.08536586165428162,\n",
       "   0.08445173501968384,\n",
       "   0.0843365415930748,\n",
       "   0.08322232961654663,\n",
       "   0.08394640684127808,\n",
       "   0.08336091786623001,\n",
       "   0.08396372199058533],\n",
       "  'val_pearson': [0.3640698194503784,\n",
       "   0.379184752702713,\n",
       "   0.3840065002441406,\n",
       "   0.39067062735557556,\n",
       "   0.3905212879180908,\n",
       "   0.3893697261810303,\n",
       "   0.39052116870880127],\n",
       "  'train_loss': [0.09612561017274857,\n",
       "   0.0850755125284195,\n",
       "   0.08420451730489731,\n",
       "   0.08376375585794449,\n",
       "   0.08357208967208862,\n",
       "   0.08343412727117538,\n",
       "   0.08326998353004456],\n",
       "  'train_pearson': [0.3002333641052246,\n",
       "   0.3713543117046356,\n",
       "   0.3815510869026184,\n",
       "   0.38704970479011536,\n",
       "   0.3899953365325928,\n",
       "   0.39171987771987915,\n",
       "   0.3937028646469116]},\n",
       " 'RBP3': {'test_loss': 0.08778701722621918,\n",
       "  'test_pearson': 0.5360462069511414,\n",
       "  'val_loss': [0.08966847509145737,\n",
       "   0.08889325708150864,\n",
       "   0.08889499306678772,\n",
       "   0.08776216953992844,\n",
       "   0.08921767771244049,\n",
       "   0.08788443356752396,\n",
       "   0.0878991186618805],\n",
       "  'val_pearson': [0.5254905223846436,\n",
       "   0.5352314114570618,\n",
       "   0.5371983051300049,\n",
       "   0.5385974049568176,\n",
       "   0.5405755043029785,\n",
       "   0.5400220155715942,\n",
       "   0.5400159955024719],\n",
       "  'train_loss': [0.09497115761041641,\n",
       "   0.08983051776885986,\n",
       "   0.08925402164459229,\n",
       "   0.08891705423593521,\n",
       "   0.08861041069030762,\n",
       "   0.08846352249383926,\n",
       "   0.08838698267936707],\n",
       "  'train_pearson': [0.5006524920463562,\n",
       "   0.5272312760353088,\n",
       "   0.5315695405006409,\n",
       "   0.5342238545417786,\n",
       "   0.536231517791748,\n",
       "   0.5377413034439087,\n",
       "   0.5380210280418396]},\n",
       " 'RBP32': {'test_loss': 0.07927266508340836,\n",
       "  'test_pearson': 0.5078359842300415,\n",
       "  'val_loss': [0.08228293806314468,\n",
       "   0.08020070195198059,\n",
       "   0.07999853789806366,\n",
       "   0.08038375526666641,\n",
       "   0.07964091747999191,\n",
       "   0.07987639307975769,\n",
       "   0.07955899834632874,\n",
       "   0.07975684851408005,\n",
       "   0.07967626303434372,\n",
       "   0.07951992005109787,\n",
       "   0.07934920489788055,\n",
       "   0.07944770157337189,\n",
       "   0.08047487586736679,\n",
       "   0.07955384999513626],\n",
       "  'val_pearson': [0.4861387312412262,\n",
       "   0.5056171417236328,\n",
       "   0.5083848237991333,\n",
       "   0.5072170495986938,\n",
       "   0.5111494660377502,\n",
       "   0.5113295912742615,\n",
       "   0.5113665461540222,\n",
       "   0.5103336572647095,\n",
       "   0.5125412940979004,\n",
       "   0.5134623050689697,\n",
       "   0.5144534111022949,\n",
       "   0.5134184956550598,\n",
       "   0.5131129026412964,\n",
       "   0.5147085785865784],\n",
       "  'train_loss': [0.08900732547044754,\n",
       "   0.0811741054058075,\n",
       "   0.08050057291984558,\n",
       "   0.08025309443473816,\n",
       "   0.07997747510671616,\n",
       "   0.07984902709722519,\n",
       "   0.07969895005226135,\n",
       "   0.07966740429401398,\n",
       "   0.07958126813173294,\n",
       "   0.07955782860517502,\n",
       "   0.07951865345239639,\n",
       "   0.07954723387956619,\n",
       "   0.07945358753204346,\n",
       "   0.07951442897319794],\n",
       "  'train_pearson': [0.45030224323272705,\n",
       "   0.5004310011863708,\n",
       "   0.5069504976272583,\n",
       "   0.509112536907196,\n",
       "   0.5105326771736145,\n",
       "   0.5117560029029846,\n",
       "   0.5129448771476746,\n",
       "   0.5135356187820435,\n",
       "   0.5139682292938232,\n",
       "   0.514754056930542,\n",
       "   0.5149791836738586,\n",
       "   0.5149048566818237,\n",
       "   0.5152044892311096,\n",
       "   0.5151236653327942]},\n",
       " 'RBP12': {'test_loss': 0.07576292008161545,\n",
       "  'test_pearson': 0.6336047649383545,\n",
       "  'val_loss': [0.07880809158086777,\n",
       "   0.07675007730722427,\n",
       "   0.07781458646059036,\n",
       "   0.07677106559276581,\n",
       "   0.07722534239292145],\n",
       "  'val_pearson': [0.6230922341346741,\n",
       "   0.6269285678863525,\n",
       "   0.6277063488960266,\n",
       "   0.6279991865158081,\n",
       "   0.6280434727668762],\n",
       "  'train_loss': [0.08400306850671768,\n",
       "   0.0770999938249588,\n",
       "   0.07683627307415009,\n",
       "   0.07669716328382492,\n",
       "   0.0766892358660698],\n",
       "  'train_pearson': [0.6086538434028625,\n",
       "   0.627702534198761,\n",
       "   0.629260241985321,\n",
       "   0.6298033595085144,\n",
       "   0.6300708651542664]},\n",
       " 'RBP4': {'test_loss': 0.09292133897542953,\n",
       "  'test_pearson': 0.38053569197654724,\n",
       "  'val_loss': [0.09349595010280609,\n",
       "   0.09452622383832932,\n",
       "   0.09300974011421204,\n",
       "   0.09377194941043854,\n",
       "   0.09291164577007294,\n",
       "   0.09380795061588287,\n",
       "   0.09410452842712402,\n",
       "   0.09307752549648285],\n",
       "  'val_pearson': [0.381272554397583,\n",
       "   0.3842768669128418,\n",
       "   0.38417649269104004,\n",
       "   0.3852311968803406,\n",
       "   0.3850676715373993,\n",
       "   0.38309091329574585,\n",
       "   0.3845895826816559,\n",
       "   0.3850134313106537],\n",
       "  'train_loss': [0.0975947231054306,\n",
       "   0.092969611287117,\n",
       "   0.09280789643526077,\n",
       "   0.09270139038562775,\n",
       "   0.0926942303776741,\n",
       "   0.09267265349626541,\n",
       "   0.0927010253071785,\n",
       "   0.09262792766094208],\n",
       "  'train_pearson': [0.3716636002063751,\n",
       "   0.3877824544906616,\n",
       "   0.3890167474746704,\n",
       "   0.3893669843673706,\n",
       "   0.3898012042045593,\n",
       "   0.3900342285633087,\n",
       "   0.3896941542625427,\n",
       "   0.3898851275444031]},\n",
       " 'RBP30': {'test_loss': 0.12076286226511002,\n",
       "  'test_pearson': 0.24042512476444244,\n",
       "  'val_loss': [0.12428300082683563,\n",
       "   0.12130433320999146,\n",
       "   0.12150608748197556,\n",
       "   0.12101544439792633,\n",
       "   0.12099982798099518,\n",
       "   0.12078416347503662,\n",
       "   0.12092118710279465,\n",
       "   0.12144962698221207,\n",
       "   0.12076772749423981,\n",
       "   0.120498888194561,\n",
       "   0.12063858658075333,\n",
       "   0.12117379158735275,\n",
       "   0.12059302628040314],\n",
       "  'val_pearson': [0.234021857380867,\n",
       "   0.23914577066898346,\n",
       "   0.2399033010005951,\n",
       "   0.24527177214622498,\n",
       "   0.24649854004383087,\n",
       "   0.24501848220825195,\n",
       "   0.24607659876346588,\n",
       "   0.24940672516822815,\n",
       "   0.2472415268421173,\n",
       "   0.2500271201133728,\n",
       "   0.2482561469078064,\n",
       "   0.24742265045642853,\n",
       "   0.2491607666015625],\n",
       "  'train_loss': [0.12602776288986206,\n",
       "   0.12175199389457703,\n",
       "   0.12137558311223984,\n",
       "   0.12123984843492508,\n",
       "   0.12093754857778549,\n",
       "   0.12089034169912338,\n",
       "   0.12083500623703003,\n",
       "   0.12076103687286377,\n",
       "   0.12073899805545807,\n",
       "   0.12077751010656357,\n",
       "   0.1207217201590538,\n",
       "   0.12069274485111237,\n",
       "   0.12068663537502289],\n",
       "  'train_pearson': [0.2198323756456375,\n",
       "   0.23718176782131195,\n",
       "   0.242217019200325,\n",
       "   0.24351324141025543,\n",
       "   0.24631738662719727,\n",
       "   0.24754853546619415,\n",
       "   0.24747972190380096,\n",
       "   0.2489088773727417,\n",
       "   0.2491876482963562,\n",
       "   0.24890029430389404,\n",
       "   0.24927543103694916,\n",
       "   0.24995383620262146,\n",
       "   0.24993020296096802]},\n",
       " 'RBP25': {'test_loss': 0.08407232165336609,\n",
       "  'test_pearson': 0.6029499173164368,\n",
       "  'val_loss': [0.08574546128511429,\n",
       "   0.08580091595649719,\n",
       "   0.0849611684679985,\n",
       "   0.08646351844072342,\n",
       "   0.08491399139165878,\n",
       "   0.08466347306966782,\n",
       "   0.08453256636857986,\n",
       "   0.08453306555747986,\n",
       "   0.08545670658349991,\n",
       "   0.08437708020210266,\n",
       "   0.08443370461463928,\n",
       "   0.08489169925451279,\n",
       "   0.08427480608224869,\n",
       "   0.08482176065444946,\n",
       "   0.08440249413251877,\n",
       "   0.08441954851150513],\n",
       "  'val_pearson': [0.5942342877388,\n",
       "   0.5972652435302734,\n",
       "   0.5990087985992432,\n",
       "   0.6004088521003723,\n",
       "   0.6014673113822937,\n",
       "   0.6024866700172424,\n",
       "   0.6027275919914246,\n",
       "   0.6029482483863831,\n",
       "   0.6025161147117615,\n",
       "   0.6032503247261047,\n",
       "   0.6032525300979614,\n",
       "   0.6035944223403931,\n",
       "   0.6037019491195679,\n",
       "   0.6025092601776123,\n",
       "   0.6033773422241211,\n",
       "   0.6026244759559631],\n",
       "  'train_loss': [0.09258853644132614,\n",
       "   0.08575751632452011,\n",
       "   0.0852968618273735,\n",
       "   0.08495207875967026,\n",
       "   0.0849369689822197,\n",
       "   0.0846746489405632,\n",
       "   0.08468920737504959,\n",
       "   0.08458561450242996,\n",
       "   0.08462224155664444,\n",
       "   0.08451362699270248,\n",
       "   0.08445340394973755,\n",
       "   0.08445635437965393,\n",
       "   0.08435936272144318,\n",
       "   0.08443158864974976,\n",
       "   0.08449872583150864,\n",
       "   0.08440395444631577],\n",
       "  'train_pearson': [0.5755522847175598,\n",
       "   0.5973218679428101,\n",
       "   0.6002378463745117,\n",
       "   0.6016762256622314,\n",
       "   0.6022725105285645,\n",
       "   0.6033328175544739,\n",
       "   0.6037523746490479,\n",
       "   0.6043093800544739,\n",
       "   0.6046555638313293,\n",
       "   0.6048961877822876,\n",
       "   0.604951798915863,\n",
       "   0.6053448915481567,\n",
       "   0.6052659153938293,\n",
       "   0.605492889881134,\n",
       "   0.6054374575614929,\n",
       "   0.6056214570999146]},\n",
       " 'RBP36': {'test_loss': 0.06443966180086136,\n",
       "  'test_pearson': 0.5511786341667175,\n",
       "  'val_loss': [0.0681711956858635,\n",
       "   0.06996931880712509,\n",
       "   0.06711637228727341,\n",
       "   0.06613770872354507,\n",
       "   0.06567970663309097,\n",
       "   0.06499850749969482,\n",
       "   0.06514443457126617,\n",
       "   0.06496141850948334,\n",
       "   0.06481114774942398,\n",
       "   0.06596656888723373,\n",
       "   0.06460961699485779,\n",
       "   0.06488298624753952,\n",
       "   0.06487720459699631,\n",
       "   0.06442239135503769,\n",
       "   0.06503808498382568,\n",
       "   0.06484124809503555,\n",
       "   0.06437712162733078,\n",
       "   0.0644816905260086,\n",
       "   0.06452353298664093,\n",
       "   0.06585711240768433],\n",
       "  'val_pearson': [0.5207117199897766,\n",
       "   0.5240908861160278,\n",
       "   0.5294334292411804,\n",
       "   0.5360229015350342,\n",
       "   0.5426209568977356,\n",
       "   0.5476530194282532,\n",
       "   0.5511997938156128,\n",
       "   0.5481473207473755,\n",
       "   0.5495529174804688,\n",
       "   0.5490321516990662,\n",
       "   0.5513013005256653,\n",
       "   0.5499460697174072,\n",
       "   0.5530146956443787,\n",
       "   0.5531516075134277,\n",
       "   0.5491011142730713,\n",
       "   0.5530009865760803,\n",
       "   0.5536116361618042,\n",
       "   0.5540840029716492,\n",
       "   0.5537805557250977,\n",
       "   0.5525979995727539],\n",
       "  'train_loss': [0.07250957190990448,\n",
       "   0.0676770955324173,\n",
       "   0.06726972758769989,\n",
       "   0.06671376526355743,\n",
       "   0.06607161462306976,\n",
       "   0.06521587073802948,\n",
       "   0.0648408979177475,\n",
       "   0.0647001788020134,\n",
       "   0.0646972730755806,\n",
       "   0.06459588557481766,\n",
       "   0.06456418335437775,\n",
       "   0.0644439160823822,\n",
       "   0.0644695907831192,\n",
       "   0.06441923975944519,\n",
       "   0.06437620520591736,\n",
       "   0.06431441754102707,\n",
       "   0.06425616890192032,\n",
       "   0.0642407163977623,\n",
       "   0.06426677107810974,\n",
       "   0.06418546289205551],\n",
       "  'train_pearson': [0.49828460812568665,\n",
       "   0.5240007042884827,\n",
       "   0.5286530256271362,\n",
       "   0.5334752798080444,\n",
       "   0.5396623015403748,\n",
       "   0.5484110713005066,\n",
       "   0.5522867441177368,\n",
       "   0.5532994866371155,\n",
       "   0.5540052652359009,\n",
       "   0.5544673204421997,\n",
       "   0.5549903512001038,\n",
       "   0.5556296706199646,\n",
       "   0.5559045672416687,\n",
       "   0.556613028049469,\n",
       "   0.5566607713699341,\n",
       "   0.5576525926589966,\n",
       "   0.5576509833335876,\n",
       "   0.5577709674835205,\n",
       "   0.5580723881721497,\n",
       "   0.558485746383667]},\n",
       " 'RBP23': {'test_loss': 0.08327086269855499,\n",
       "  'test_pearson': 0.6722136735916138,\n",
       "  'val_loss': [0.0844302624464035,\n",
       "   0.08480429649353027,\n",
       "   0.0840151309967041,\n",
       "   0.08459635078907013,\n",
       "   0.08397822827100754,\n",
       "   0.08451787382364273,\n",
       "   0.08379652351140976,\n",
       "   0.08339709788560867,\n",
       "   0.08348637819290161,\n",
       "   0.08366101235151291,\n",
       "   0.0836048498749733],\n",
       "  'val_pearson': [0.6688644289970398,\n",
       "   0.6705639958381653,\n",
       "   0.671790361404419,\n",
       "   0.6722902059555054,\n",
       "   0.6715079545974731,\n",
       "   0.673291027545929,\n",
       "   0.6734491586685181,\n",
       "   0.6744787096977234,\n",
       "   0.6752414107322693,\n",
       "   0.6744667291641235,\n",
       "   0.6741279363632202],\n",
       "  'train_loss': [0.09835656732320786,\n",
       "   0.0853920578956604,\n",
       "   0.08464455604553223,\n",
       "   0.08431467413902283,\n",
       "   0.08410321921110153,\n",
       "   0.08392525464296341,\n",
       "   0.08378652483224869,\n",
       "   0.08368274569511414,\n",
       "   0.08367224782705307,\n",
       "   0.08348432928323746,\n",
       "   0.0835612565279007],\n",
       "  'train_pearson': [0.6391844749450684,\n",
       "   0.6686888337135315,\n",
       "   0.6709972023963928,\n",
       "   0.6724194884300232,\n",
       "   0.6740875840187073,\n",
       "   0.6745100021362305,\n",
       "   0.6752091646194458,\n",
       "   0.6755174398422241,\n",
       "   0.6759882569313049,\n",
       "   0.6766852140426636,\n",
       "   0.6767668724060059]},\n",
       " 'RBP13': {'test_loss': 0.08774139732122421,\n",
       "  'test_pearson': 0.47808828949928284,\n",
       "  'val_loss': [0.09246000647544861,\n",
       "   0.09128259867429733,\n",
       "   0.09038957953453064,\n",
       "   0.08997408300638199,\n",
       "   0.08862052112817764,\n",
       "   0.08850137889385223,\n",
       "   0.08822979032993317,\n",
       "   0.08822599798440933,\n",
       "   0.08837171643972397,\n",
       "   0.08894025534391403,\n",
       "   0.08798081427812576,\n",
       "   0.08898700028657913,\n",
       "   0.08861949294805527,\n",
       "   0.08840116113424301],\n",
       "  'val_pearson': [0.4472377598285675,\n",
       "   0.45890334248542786,\n",
       "   0.46181005239486694,\n",
       "   0.463982492685318,\n",
       "   0.4749080240726471,\n",
       "   0.4768297076225281,\n",
       "   0.4789314866065979,\n",
       "   0.48103323578834534,\n",
       "   0.47902384400367737,\n",
       "   0.47441190481185913,\n",
       "   0.48076409101486206,\n",
       "   0.4805452227592468,\n",
       "   0.4782692790031433,\n",
       "   0.4807946979999542],\n",
       "  'train_loss': [0.09768494218587875,\n",
       "   0.09127285331487656,\n",
       "   0.09043675661087036,\n",
       "   0.09007935971021652,\n",
       "   0.0891590341925621,\n",
       "   0.08861616253852844,\n",
       "   0.08838143199682236,\n",
       "   0.08821021765470505,\n",
       "   0.088106170296669,\n",
       "   0.08806014060974121,\n",
       "   0.0878976359963417,\n",
       "   0.08793101459741592,\n",
       "   0.08785592764616013,\n",
       "   0.08781297504901886],\n",
       "  'train_pearson': [0.4235677719116211,\n",
       "   0.4537610411643982,\n",
       "   0.46107399463653564,\n",
       "   0.4644787013530731,\n",
       "   0.47324493527412415,\n",
       "   0.47801294922828674,\n",
       "   0.4802498519420624,\n",
       "   0.48192188143730164,\n",
       "   0.483187735080719,\n",
       "   0.48380953073501587,\n",
       "   0.4845571517944336,\n",
       "   0.48469632863998413,\n",
       "   0.4851393699645996,\n",
       "   0.4856216311454773]},\n",
       " 'RBP6': {'test_loss': 0.08190469443798065,\n",
       "  'test_pearson': 0.22820214927196503,\n",
       "  'val_loss': [0.08311988413333893,\n",
       "   0.08224162459373474,\n",
       "   0.08188416063785553,\n",
       "   0.08344703912734985,\n",
       "   0.08175170421600342,\n",
       "   0.08534892648458481,\n",
       "   0.08332283794879913,\n",
       "   0.08280684798955917],\n",
       "  'val_pearson': [0.2081933319568634,\n",
       "   0.22453060746192932,\n",
       "   0.23195581138134003,\n",
       "   0.22939424216747284,\n",
       "   0.2355508953332901,\n",
       "   0.23597800731658936,\n",
       "   0.233437180519104,\n",
       "   0.2330014556646347],\n",
       "  'train_loss': [0.11117111146450043,\n",
       "   0.08288118243217468,\n",
       "   0.08212830871343613,\n",
       "   0.08200063556432724,\n",
       "   0.0817958414554596,\n",
       "   0.08159888535737991,\n",
       "   0.0816381424665451,\n",
       "   0.08131027221679688],\n",
       "  'train_pearson': [0.13478058576583862,\n",
       "   0.22314955294132233,\n",
       "   0.24058812856674194,\n",
       "   0.24824655055999756,\n",
       "   0.25296083092689514,\n",
       "   0.25621816515922546,\n",
       "   0.25912508368492126,\n",
       "   0.2603493928909302]},\n",
       " 'RBP2': {'test_loss': 0.10636033117771149,\n",
       "  'test_pearson': 0.5985762476921082,\n",
       "  'val_loss': [0.11508626490831375,\n",
       "   0.110965795814991,\n",
       "   0.10914257168769836,\n",
       "   0.10732042789459229,\n",
       "   0.10735355317592621,\n",
       "   0.10692263394594193,\n",
       "   0.10725845396518707,\n",
       "   0.10703965276479721,\n",
       "   0.10715007781982422],\n",
       "  'val_pearson': [0.5658345818519592,\n",
       "   0.5813230872154236,\n",
       "   0.5895354747772217,\n",
       "   0.5944685339927673,\n",
       "   0.5965767502784729,\n",
       "   0.5969215631484985,\n",
       "   0.5982813239097595,\n",
       "   0.6011756062507629,\n",
       "   0.5976694822311401],\n",
       "  'train_loss': [0.12646235525608063,\n",
       "   0.11191345751285553,\n",
       "   0.10945639759302139,\n",
       "   0.10839436948299408,\n",
       "   0.10763059556484222,\n",
       "   0.1069820374250412,\n",
       "   0.1066264882683754,\n",
       "   0.10626038908958435,\n",
       "   0.10615736991167068],\n",
       "  'train_pearson': [0.5320912003517151,\n",
       "   0.5736694931983948,\n",
       "   0.5863757133483887,\n",
       "   0.5918317437171936,\n",
       "   0.5950536131858826,\n",
       "   0.5983719229698181,\n",
       "   0.6004650592803955,\n",
       "   0.6015937328338623,\n",
       "   0.6026566624641418]},\n",
       " 'RBP34': {'test_loss': 0.0744229331612587,\n",
       "  'test_pearson': 0.5402108430862427,\n",
       "  'val_loss': [0.07814887166023254,\n",
       "   0.07622923702001572,\n",
       "   0.07631717622280121,\n",
       "   0.07560327649116516,\n",
       "   0.07544829696416855,\n",
       "   0.0752192959189415,\n",
       "   0.07581710815429688,\n",
       "   0.07487387210130692,\n",
       "   0.07507532835006714,\n",
       "   0.07743997126817703,\n",
       "   0.07539232820272446],\n",
       "  'val_pearson': [0.5141202807426453,\n",
       "   0.5312586426734924,\n",
       "   0.5372205376625061,\n",
       "   0.5381970405578613,\n",
       "   0.5392173528671265,\n",
       "   0.5393306016921997,\n",
       "   0.5401663184165955,\n",
       "   0.5425314903259277,\n",
       "   0.5417617559432983,\n",
       "   0.5404277443885803,\n",
       "   0.542174756526947],\n",
       "  'train_loss': [0.08651397377252579,\n",
       "   0.07714392244815826,\n",
       "   0.0761316567659378,\n",
       "   0.07565762847661972,\n",
       "   0.07558156549930573,\n",
       "   0.07535648345947266,\n",
       "   0.07520166784524918,\n",
       "   0.07519765943288803,\n",
       "   0.0751308724284172,\n",
       "   0.0750926211476326,\n",
       "   0.07501291483640671],\n",
       "  'train_pearson': [nan,\n",
       "   0.5254301428794861,\n",
       "   0.5351241827011108,\n",
       "   0.5379436612129211,\n",
       "   0.5399537086486816,\n",
       "   0.5415714383125305,\n",
       "   0.5423320531845093,\n",
       "   0.5432641506195068,\n",
       "   0.5441092848777771,\n",
       "   0.5442682504653931,\n",
       "   0.5445697903633118]},\n",
       " 'RBP19': {'test_loss': 0.08712582290172577,\n",
       "  'test_pearson': 0.6394930481910706,\n",
       "  'val_loss': [0.08990705758333206,\n",
       "   0.09005378931760788,\n",
       "   0.09020281583070755,\n",
       "   0.08977040648460388,\n",
       "   0.08982738852500916,\n",
       "   0.09021875262260437,\n",
       "   0.08861564844846725,\n",
       "   0.08859635889530182,\n",
       "   0.09049730002880096,\n",
       "   0.08826316148042679,\n",
       "   0.0902378186583519,\n",
       "   0.08796118944883347,\n",
       "   0.08899220824241638,\n",
       "   0.08912064880132675,\n",
       "   0.08901278674602509],\n",
       "  'val_pearson': [0.6259573101997375,\n",
       "   0.6302027702331543,\n",
       "   0.6337729692459106,\n",
       "   0.632927417755127,\n",
       "   0.6335049271583557,\n",
       "   0.6245417594909668,\n",
       "   0.6347787380218506,\n",
       "   0.636191189289093,\n",
       "   0.6355219483375549,\n",
       "   0.6348644495010376,\n",
       "   0.6360079050064087,\n",
       "   0.635980486869812,\n",
       "   0.6346529722213745,\n",
       "   0.6318886280059814,\n",
       "   0.6362825036048889],\n",
       "  'train_loss': [0.09465784579515457,\n",
       "   0.08951286226511002,\n",
       "   0.08883780241012573,\n",
       "   0.08808387815952301,\n",
       "   0.08784523606300354,\n",
       "   0.0878630056977272,\n",
       "   0.0876026451587677,\n",
       "   0.08750106394290924,\n",
       "   0.0872933566570282,\n",
       "   0.08720874041318893,\n",
       "   0.0870579406619072,\n",
       "   0.08726118505001068,\n",
       "   0.0872439444065094,\n",
       "   0.08704674988985062,\n",
       "   0.0869913175702095],\n",
       "  'train_pearson': [0.6117591857910156,\n",
       "   0.6317223310470581,\n",
       "   0.6351613402366638,\n",
       "   0.6386220455169678,\n",
       "   0.6396633982658386,\n",
       "   0.6402090787887573,\n",
       "   0.6415373682975769,\n",
       "   0.6419680714607239,\n",
       "   0.6428335309028625,\n",
       "   0.6430248618125916,\n",
       "   0.6433507204055786,\n",
       "   0.6435567140579224,\n",
       "   0.6435360312461853,\n",
       "   0.643850564956665,\n",
       "   0.6438933610916138]},\n",
       " 'RBP8': {'test_loss': 0.0948973000049591,\n",
       "  'test_pearson': 0.1989498734474182,\n",
       "  'val_loss': [0.09608349949121475,\n",
       "   0.09466858208179474,\n",
       "   0.09496375173330307,\n",
       "   0.09493391215801239,\n",
       "   0.09500639885663986],\n",
       "  'val_pearson': [0.21084442734718323,\n",
       "   0.21333524584770203,\n",
       "   0.2123110443353653,\n",
       "   0.21107545495033264,\n",
       "   0.20511895418167114],\n",
       "  'train_loss': [0.09926352649927139,\n",
       "   0.09512355923652649,\n",
       "   0.0950223058462143,\n",
       "   0.09498341381549835,\n",
       "   0.09498012065887451],\n",
       "  'train_pearson': [0.1880163997411728,\n",
       "   0.2091505378484726,\n",
       "   0.2097243219614029,\n",
       "   0.2100047618150711,\n",
       "   0.20995572209358215]},\n",
       " 'RBP1': {'test_loss': 0.07741265743970871,\n",
       "  'test_pearson': 0.6326812505722046,\n",
       "  'val_loss': [0.07844938337802887,\n",
       "   0.07852959632873535,\n",
       "   0.07765872031450272,\n",
       "   0.07828433811664581,\n",
       "   0.07823017984628677,\n",
       "   0.07837750762701035],\n",
       "  'val_pearson': [0.627009391784668,\n",
       "   0.6294637322425842,\n",
       "   0.6320820450782776,\n",
       "   0.630588948726654,\n",
       "   0.6323758959770203,\n",
       "   0.6283031702041626],\n",
       "  'train_loss': [0.0833977609872818,\n",
       "   0.0790308341383934,\n",
       "   0.07853706926107407,\n",
       "   0.07827096432447433,\n",
       "   0.07820778340101242,\n",
       "   0.07816363871097565],\n",
       "  'train_pearson': [0.6023939251899719,\n",
       "   0.6271832585334778,\n",
       "   0.6302059292793274,\n",
       "   0.6315488219261169,\n",
       "   0.6317812204360962,\n",
       "   0.6321118474006653]},\n",
       " 'RBP16': {'test_loss': 0.10470584779977798,\n",
       "  'test_pearson': 0.5145425796508789,\n",
       "  'val_loss': [0.10490822792053223,\n",
       "   0.10469099134206772,\n",
       "   0.1042569950222969,\n",
       "   0.10435562580823898,\n",
       "   0.10373280197381973,\n",
       "   0.1046241968870163,\n",
       "   0.10374179482460022,\n",
       "   0.10404054075479507],\n",
       "  'val_pearson': [0.5173009634017944,\n",
       "   0.5189010500907898,\n",
       "   0.5220175385475159,\n",
       "   0.5218850374221802,\n",
       "   0.5247003436088562,\n",
       "   0.5241579413414001,\n",
       "   0.5244630575180054,\n",
       "   0.5257675647735596],\n",
       "  'train_loss': [0.11803208291530609,\n",
       "   0.1057124212384224,\n",
       "   0.10516470670700073,\n",
       "   0.10492604970932007,\n",
       "   0.10481603443622589,\n",
       "   0.1046069860458374,\n",
       "   0.10445985198020935,\n",
       "   0.10438748449087143],\n",
       "  'train_pearson': [nan,\n",
       "   0.5143168568611145,\n",
       "   0.5175513029098511,\n",
       "   0.5192197561264038,\n",
       "   0.5201616883277893,\n",
       "   0.5215632915496826,\n",
       "   0.5222883820533752,\n",
       "   0.5227907299995422]},\n",
       " 'RBP5': {'test_loss': 0.06343109160661697,\n",
       "  'test_pearson': 0.2697131335735321,\n",
       "  'val_loss': [0.063988097012043,\n",
       "   0.06358394026756287,\n",
       "   0.063845194876194,\n",
       "   0.0638711228966713,\n",
       "   0.06405451148748398],\n",
       "  'val_pearson': [0.2799099385738373,\n",
       "   0.28411945700645447,\n",
       "   0.28399813175201416,\n",
       "   0.2814107835292816,\n",
       "   0.2803051769733429],\n",
       "  'train_loss': [0.06823280453681946,\n",
       "   0.06411764025688171,\n",
       "   0.06405040621757507,\n",
       "   0.0639820247888565,\n",
       "   0.06387363374233246],\n",
       "  'train_pearson': [0.26998865604400635,\n",
       "   0.28321781754493713,\n",
       "   0.28352662920951843,\n",
       "   0.2839987277984619,\n",
       "   0.28509846329689026]},\n",
       " 'RBP17': {'test_loss': 0.07176375389099121,\n",
       "  'test_pearson': 0.48035678267478943,\n",
       "  'val_loss': [0.07365526258945465,\n",
       "   0.07287575304508209,\n",
       "   0.07225517183542252,\n",
       "   0.07222756743431091,\n",
       "   0.07187313586473465,\n",
       "   0.07225950062274933,\n",
       "   0.07183166593313217,\n",
       "   0.07318103313446045,\n",
       "   0.07158669829368591,\n",
       "   0.07500263303518295,\n",
       "   0.07181217521429062,\n",
       "   0.07264561951160431],\n",
       "  'val_pearson': [0.4735231101512909,\n",
       "   0.47865521907806396,\n",
       "   0.4818052351474762,\n",
       "   0.48137167096138,\n",
       "   0.48478806018829346,\n",
       "   0.4849981963634491,\n",
       "   0.4855951964855194,\n",
       "   0.4853215515613556,\n",
       "   0.48701414465904236,\n",
       "   0.4852254092693329,\n",
       "   0.4846256673336029,\n",
       "   0.485233336687088],\n",
       "  'train_loss': [0.0853683352470398,\n",
       "   0.07902899384498596,\n",
       "   0.0782095417380333,\n",
       "   0.07802856713533401,\n",
       "   0.07775204628705978,\n",
       "   0.0776849165558815,\n",
       "   0.07772195339202881,\n",
       "   0.07760820537805557,\n",
       "   0.07746648788452148,\n",
       "   0.07740295678377151,\n",
       "   0.077429860830307,\n",
       "   0.07729079574346542],\n",
       "  'train_pearson': [0.46120336651802063,\n",
       "   0.4810689687728882,\n",
       "   0.48638391494750977,\n",
       "   0.4882242977619171,\n",
       "   0.4901256561279297,\n",
       "   0.49126508831977844,\n",
       "   0.49170297384262085,\n",
       "   0.4921663701534271,\n",
       "   0.49307000637054443,\n",
       "   0.49324318766593933,\n",
       "   0.4936355650424957,\n",
       "   0.4940647780895233]},\n",
       " 'RBP11': {'test_loss': 0.07586684823036194,\n",
       "  'test_pearson': 0.6323387622833252,\n",
       "  'val_loss': [0.07832533866167068,\n",
       "   0.07693929970264435,\n",
       "   0.07691370695829391,\n",
       "   0.07780542969703674,\n",
       "   0.07722644507884979,\n",
       "   0.07679141312837601,\n",
       "   0.07685448229312897,\n",
       "   0.07699336111545563,\n",
       "   0.0768766775727272],\n",
       "  'val_pearson': [0.6164164543151855,\n",
       "   0.6250435709953308,\n",
       "   0.6255857348442078,\n",
       "   0.625420093536377,\n",
       "   0.6262183785438538,\n",
       "   0.6261468529701233,\n",
       "   0.6262697577476501,\n",
       "   0.6251352429389954,\n",
       "   0.6259194016456604],\n",
       "  'train_loss': [0.08638360351324081,\n",
       "   0.07796361297369003,\n",
       "   0.07700851559638977,\n",
       "   0.0768817737698555,\n",
       "   0.07685375213623047,\n",
       "   0.07677678018808365,\n",
       "   0.07675287127494812,\n",
       "   0.07674635201692581,\n",
       "   0.07676830887794495],\n",
       "  'train_pearson': [0.6026654839515686,\n",
       "   0.6214316487312317,\n",
       "   0.6273431777954102,\n",
       "   0.6279650926589966,\n",
       "   0.6282874941825867,\n",
       "   0.628510057926178,\n",
       "   0.6285431981086731,\n",
       "   0.628688633441925,\n",
       "   0.6289054155349731]},\n",
       " 'RBP33': {'test_loss': 0.07321241497993469,\n",
       "  'test_pearson': 0.5513588786125183,\n",
       "  'val_loss': [0.07573734223842621,\n",
       "   0.07554112374782562,\n",
       "   0.07596927136182785,\n",
       "   0.07534582167863846,\n",
       "   0.0741904154419899,\n",
       "   0.07399880886077881,\n",
       "   0.07538694888353348,\n",
       "   0.0735277608036995,\n",
       "   0.07369404286146164,\n",
       "   0.0757238119840622,\n",
       "   0.07371021807193756],\n",
       "  'val_pearson': [0.5406445264816284,\n",
       "   0.5437743067741394,\n",
       "   0.5466216802597046,\n",
       "   0.5535217523574829,\n",
       "   0.5534639358520508,\n",
       "   0.5547972321510315,\n",
       "   0.5453206300735474,\n",
       "   0.5542968511581421,\n",
       "   0.5556622743606567,\n",
       "   0.5536572337150574,\n",
       "   0.5543041825294495],\n",
       "  'train_loss': [0.07801195234060287,\n",
       "   0.0752701386809349,\n",
       "   0.07482017576694489,\n",
       "   0.07429260015487671,\n",
       "   0.07400939613580704,\n",
       "   0.0738435760140419,\n",
       "   0.07378074526786804,\n",
       "   0.0737777054309845,\n",
       "   0.07373025268316269,\n",
       "   0.07366010546684265,\n",
       "   0.07366343587636948],\n",
       "  'train_pearson': [0.5212426781654358,\n",
       "   0.5433595776557922,\n",
       "   0.5468969345092773,\n",
       "   0.5510182976722717,\n",
       "   0.5534436702728271,\n",
       "   0.5544779896736145,\n",
       "   0.555785596370697,\n",
       "   0.5557816624641418,\n",
       "   0.5561403036117554,\n",
       "   0.556602954864502,\n",
       "   0.5564265251159668]},\n",
       " 'RBP9': {'test_loss': 0.09641962498426437,\n",
       "  'test_pearson': 0.4427846670150757,\n",
       "  'val_loss': [0.09756392985582352,\n",
       "   0.09707477688789368,\n",
       "   0.09764540195465088,\n",
       "   0.097190260887146,\n",
       "   0.09652885794639587,\n",
       "   0.09711983054876328,\n",
       "   0.09596380591392517,\n",
       "   0.09653352200984955,\n",
       "   0.09730423241853714,\n",
       "   0.0975269302725792],\n",
       "  'val_pearson': [0.4373069107532501,\n",
       "   0.4412165582180023,\n",
       "   0.4405304491519928,\n",
       "   0.4493301510810852,\n",
       "   0.44818153977394104,\n",
       "   0.45021042227745056,\n",
       "   0.4518382251262665,\n",
       "   0.45004895329475403,\n",
       "   0.4473184049129486,\n",
       "   0.4496594965457916],\n",
       "  'train_loss': [0.10341722518205643,\n",
       "   0.09847463667392731,\n",
       "   0.09797333180904388,\n",
       "   0.09754234552383423,\n",
       "   0.09736838191747665,\n",
       "   0.09719337522983551,\n",
       "   0.09708739072084427,\n",
       "   0.0970764309167862,\n",
       "   0.09692008793354034,\n",
       "   0.09692400693893433],\n",
       "  'train_pearson': [0.41387414932250977,\n",
       "   0.430583655834198,\n",
       "   0.435313880443573,\n",
       "   0.4391428828239441,\n",
       "   0.4411426782608032,\n",
       "   0.44214382767677307,\n",
       "   0.44314050674438477,\n",
       "   0.44338610768318176,\n",
       "   0.44431057572364807,\n",
       "   0.44487616419792175]},\n",
       " 'RBP20': {'test_loss': 0.10968053340911865,\n",
       "  'test_pearson': 0.2589189410209656,\n",
       "  'val_loss': [0.1120779812335968,\n",
       "   0.11119481176137924,\n",
       "   0.11129943281412125,\n",
       "   0.11162347346544266,\n",
       "   0.11066970229148865,\n",
       "   0.11041871458292007,\n",
       "   0.11027737706899643,\n",
       "   0.11033550649881363,\n",
       "   0.11024308204650879,\n",
       "   0.11024237424135208,\n",
       "   0.11005835235118866,\n",
       "   0.11027226597070694,\n",
       "   0.10985543578863144,\n",
       "   0.11049585789442062,\n",
       "   0.10992886871099472,\n",
       "   0.11020396649837494],\n",
       "  'val_pearson': [0.2365214079618454,\n",
       "   0.2403094470500946,\n",
       "   0.2370806187391281,\n",
       "   0.23682667315006256,\n",
       "   0.250180184841156,\n",
       "   0.25469717383384705,\n",
       "   0.2550849914550781,\n",
       "   0.25408825278282166,\n",
       "   0.25655820965766907,\n",
       "   0.25726911425590515,\n",
       "   0.2590498626232147,\n",
       "   0.2623435854911804,\n",
       "   0.2629622220993042,\n",
       "   0.2649703621864319,\n",
       "   0.26553067564964294,\n",
       "   0.2587491571903229],\n",
       "  'train_loss': [0.11563263088464737,\n",
       "   0.11133828014135361,\n",
       "   0.11116133630275726,\n",
       "   0.11099828034639359,\n",
       "   0.11074837297201157,\n",
       "   0.11026135832071304,\n",
       "   0.11011654138565063,\n",
       "   0.11005993187427521,\n",
       "   0.10998526215553284,\n",
       "   0.10988005250692368,\n",
       "   0.1097380593419075,\n",
       "   0.1095963716506958,\n",
       "   0.10953447222709656,\n",
       "   0.10944750159978867,\n",
       "   0.10945966839790344,\n",
       "   0.10934966802597046],\n",
       "  'train_pearson': [0.223457470536232,\n",
       "   0.24413645267486572,\n",
       "   0.24656854569911957,\n",
       "   0.24781478941440582,\n",
       "   0.2522967457771301,\n",
       "   0.26004722714424133,\n",
       "   0.2618234157562256,\n",
       "   0.26290032267570496,\n",
       "   0.26329413056373596,\n",
       "   0.2643611431121826,\n",
       "   0.26720309257507324,\n",
       "   0.26938167214393616,\n",
       "   0.27058297395706177,\n",
       "   0.2722955644130707,\n",
       "   0.2722494304180145,\n",
       "   0.2728217840194702]},\n",
       " 'RBP10': {'test_loss': 0.10861218720674515,\n",
       "  'test_pearson': 0.43799248337745667,\n",
       "  'val_loss': [0.10943745821714401,\n",
       "   0.10860653966665268,\n",
       "   0.10831589251756668,\n",
       "   0.10819137096405029,\n",
       "   0.10875510424375534,\n",
       "   0.10799803584814072,\n",
       "   0.10792037844657898,\n",
       "   0.10935164988040924,\n",
       "   0.10823853313922882,\n",
       "   0.10899362713098526],\n",
       "  'val_pearson': [0.4327338933944702,\n",
       "   0.4387529492378235,\n",
       "   0.44151967763900757,\n",
       "   0.44264471530914307,\n",
       "   0.44605231285095215,\n",
       "   0.4463612735271454,\n",
       "   0.4447503387928009,\n",
       "   0.44642823934555054,\n",
       "   0.4439992308616638,\n",
       "   0.44520795345306396],\n",
       "  'train_loss': [0.11761781573295593,\n",
       "   0.1100771427154541,\n",
       "   0.10936205834150314,\n",
       "   0.1090635284781456,\n",
       "   0.10896162688732147,\n",
       "   0.10880086570978165,\n",
       "   0.10869169235229492,\n",
       "   0.10857243090867996,\n",
       "   0.10844096541404724,\n",
       "   0.10843163728713989],\n",
       "  'train_pearson': [0.3929128050804138,\n",
       "   0.43108972907066345,\n",
       "   0.4367559254169464,\n",
       "   0.4390670657157898,\n",
       "   0.44027894735336304,\n",
       "   0.44165730476379395,\n",
       "   0.4425261318683624,\n",
       "   0.44348105788230896,\n",
       "   0.44428950548171997,\n",
       "   0.44446009397506714]},\n",
       " 'RBP26': {'test_loss': 0.08237765729427338,\n",
       "  'test_pearson': 0.6139443516731262,\n",
       "  'val_loss': [0.08404985815286636,\n",
       "   0.08328351378440857,\n",
       "   0.08454407006502151,\n",
       "   0.08446551114320755,\n",
       "   0.08298712223768234,\n",
       "   0.08559579402208328,\n",
       "   0.08318331092596054,\n",
       "   0.08280138671398163,\n",
       "   0.08427746593952179,\n",
       "   0.08245796710252762,\n",
       "   0.08247368037700653,\n",
       "   0.08436328917741776,\n",
       "   0.08328959345817566],\n",
       "  'val_pearson': [0.6051102876663208,\n",
       "   0.6106023788452148,\n",
       "   0.6121408939361572,\n",
       "   0.6136922240257263,\n",
       "   0.6134799122810364,\n",
       "   0.6137185096740723,\n",
       "   0.6105935573577881,\n",
       "   0.6136823892593384,\n",
       "   0.6097050309181213,\n",
       "   0.6154541373252869,\n",
       "   0.6146989464759827,\n",
       "   0.6106288433074951,\n",
       "   0.614900529384613],\n",
       "  'train_loss': [0.09195155650377274,\n",
       "   0.08399058878421783,\n",
       "   0.08352243155241013,\n",
       "   0.08319137990474701,\n",
       "   0.08310435712337494,\n",
       "   0.08302134275436401,\n",
       "   0.08306799829006195,\n",
       "   0.08290397375822067,\n",
       "   0.08292271941900253,\n",
       "   0.08273190259933472,\n",
       "   0.08261561393737793,\n",
       "   0.08257059752941132,\n",
       "   0.08248468488454819],\n",
       "  'train_pearson': [0.5809151530265808,\n",
       "   0.6085993051528931,\n",
       "   0.6119498014450073,\n",
       "   0.6133875846862793,\n",
       "   0.6138975024223328,\n",
       "   0.6147103309631348,\n",
       "   0.6150841116905212,\n",
       "   0.6152061223983765,\n",
       "   0.6152777075767517,\n",
       "   0.6161593794822693,\n",
       "   0.6166486740112305,\n",
       "   0.6168491840362549,\n",
       "   0.6167949438095093]},\n",
       " 'RBP18': {'test_loss': 0.10073030740022659,\n",
       "  'test_pearson': 0.5254213213920593,\n",
       "  'val_loss': [0.1069590225815773,\n",
       "   0.10338874906301498,\n",
       "   0.10269564390182495,\n",
       "   0.10182558745145798,\n",
       "   0.10155890882015228,\n",
       "   0.10157796740531921,\n",
       "   0.10092592984437943,\n",
       "   0.10180177539587021,\n",
       "   0.10065662860870361,\n",
       "   0.1006695032119751,\n",
       "   0.10141684859991074,\n",
       "   0.10088348388671875],\n",
       "  'val_pearson': [0.508747935295105,\n",
       "   0.5162025690078735,\n",
       "   0.5245346426963806,\n",
       "   0.5275390148162842,\n",
       "   0.5252565145492554,\n",
       "   0.528287410736084,\n",
       "   0.5284502506256104,\n",
       "   0.5281317234039307,\n",
       "   0.5284181237220764,\n",
       "   0.5286592245101929,\n",
       "   0.5283406376838684,\n",
       "   0.5306769609451294],\n",
       "  'train_loss': [0.11214963346719742,\n",
       "   0.10285302251577377,\n",
       "   0.10170847177505493,\n",
       "   0.10127539187669754,\n",
       "   0.10106078535318375,\n",
       "   0.10088632255792618,\n",
       "   0.10078278183937073,\n",
       "   0.10077711194753647,\n",
       "   0.10060086101293564,\n",
       "   0.10059258341789246,\n",
       "   0.10057823359966278,\n",
       "   0.10049410164356232],\n",
       "  'train_pearson': [0.49109548330307007,\n",
       "   0.5185122489929199,\n",
       "   0.5253446102142334,\n",
       "   0.528645932674408,\n",
       "   0.529980480670929,\n",
       "   0.5308806300163269,\n",
       "   0.5314425230026245,\n",
       "   0.5313618779182434,\n",
       "   0.5317911505699158,\n",
       "   0.5318838953971863,\n",
       "   0.5323341488838196,\n",
       "   0.5329660773277283]},\n",
       " 'RBP28': {'test_loss': 0.10984448343515396,\n",
       "  'test_pearson': 0.4887467920780182,\n",
       "  'val_loss': [0.11467229574918747,\n",
       "   0.11546619981527328,\n",
       "   0.1141207292675972,\n",
       "   0.11193783581256866,\n",
       "   0.11205326020717621,\n",
       "   0.11075866222381592,\n",
       "   0.11253975331783295,\n",
       "   0.10924548655748367,\n",
       "   0.10983628034591675,\n",
       "   0.10941813141107559,\n",
       "   0.11038673669099808],\n",
       "  'val_pearson': [0.45535001158714294,\n",
       "   0.4649590253829956,\n",
       "   0.4696829915046692,\n",
       "   0.47751709818840027,\n",
       "   0.48547887802124023,\n",
       "   0.48864448070526123,\n",
       "   0.484628289937973,\n",
       "   0.4957655072212219,\n",
       "   0.49148428440093994,\n",
       "   0.4935254454612732,\n",
       "   0.4919748604297638],\n",
       "  'train_loss': [0.12521900236606598,\n",
       "   0.1148223876953125,\n",
       "   0.11404187232255936,\n",
       "   0.11316993087530136,\n",
       "   0.111676886677742,\n",
       "   0.11111896485090256,\n",
       "   0.11055803298950195,\n",
       "   0.11025138944387436,\n",
       "   0.11003432422876358,\n",
       "   0.10987588763237,\n",
       "   0.10976725816726685],\n",
       "  'train_pearson': [0.39793020486831665,\n",
       "   0.4585924446582794,\n",
       "   0.4639986455440521,\n",
       "   0.4704872667789459,\n",
       "   0.48056307435035706,\n",
       "   0.48494067788124084,\n",
       "   0.48844626545906067,\n",
       "   0.49083152413368225,\n",
       "   0.49266934394836426,\n",
       "   0.4932997226715088,\n",
       "   0.4943957030773163]},\n",
       " 'RBP37': {'test_loss': 0.0730680599808693,\n",
       "  'test_pearson': 0.581122100353241,\n",
       "  'val_loss': [0.07643058896064758,\n",
       "   0.07550273835659027,\n",
       "   0.07521849870681763,\n",
       "   0.0746830403804779,\n",
       "   0.07446540892124176,\n",
       "   0.07429100573062897,\n",
       "   0.07450397312641144,\n",
       "   0.07489625364542007,\n",
       "   0.07682958245277405],\n",
       "  'val_pearson': [0.5575284361839294,\n",
       "   0.5623109936714172,\n",
       "   0.5685417056083679,\n",
       "   0.570762038230896,\n",
       "   0.5711449384689331,\n",
       "   0.5719916224479675,\n",
       "   0.5731810927391052,\n",
       "   0.5711878538131714,\n",
       "   0.5737794637680054],\n",
       "  'train_loss': [0.09114422649145126,\n",
       "   0.07573088258504868,\n",
       "   0.07514335215091705,\n",
       "   0.07437466830015182,\n",
       "   0.07409387081861496,\n",
       "   0.07391331344842911,\n",
       "   0.07365616410970688,\n",
       "   0.07374364882707596,\n",
       "   0.07362714409828186],\n",
       "  'train_pearson': [0.5193803906440735,\n",
       "   0.5660521388053894,\n",
       "   0.569868266582489,\n",
       "   0.5750352740287781,\n",
       "   0.5773943662643433,\n",
       "   0.5792138576507568,\n",
       "   0.5799401998519897,\n",
       "   0.5801658630371094,\n",
       "   0.5811349749565125]},\n",
       " 'RBP15': {'test_loss': 0.10245868563652039,\n",
       "  'test_pearson': 0.5302857160568237,\n",
       "  'val_loss': [0.10475771129131317,\n",
       "   0.10271934419870377,\n",
       "   0.10182221233844757,\n",
       "   0.10300590097904205,\n",
       "   0.10173031687736511,\n",
       "   0.1021258756518364,\n",
       "   0.10112731903791428,\n",
       "   0.10177493095397949,\n",
       "   0.10147212445735931,\n",
       "   0.10154592245817184],\n",
       "  'val_pearson': [0.5258631110191345,\n",
       "   0.5336211919784546,\n",
       "   0.5375009179115295,\n",
       "   0.5295844078063965,\n",
       "   0.5404051542282104,\n",
       "   0.5426604747772217,\n",
       "   0.5430045127868652,\n",
       "   0.5392321348190308,\n",
       "   0.5408806204795837,\n",
       "   0.5397589802742004],\n",
       "  'train_loss': [0.11539065837860107,\n",
       "   0.1037551686167717,\n",
       "   0.10295366495847702,\n",
       "   0.10255260020494461,\n",
       "   0.10238075256347656,\n",
       "   0.1022910624742508,\n",
       "   0.10207095742225647,\n",
       "   0.10204034298658371,\n",
       "   0.10184552520513535,\n",
       "   0.10193832218647003],\n",
       "  'train_pearson': [0.5008368492126465,\n",
       "   0.5278228521347046,\n",
       "   0.5323081016540527,\n",
       "   0.534864068031311,\n",
       "   0.5358312726020813,\n",
       "   0.5369288921356201,\n",
       "   0.5377991199493408,\n",
       "   0.5383546352386475,\n",
       "   0.539366602897644,\n",
       "   0.539440929889679]},\n",
       " 'RBP38': {'test_loss': 0.08574000000953674,\n",
       "  'test_pearson': 0.2278282195329666,\n",
       "  'val_loss': [0.08772348612546921,\n",
       "   0.08686058223247528,\n",
       "   0.08650130033493042,\n",
       "   0.08639593422412872,\n",
       "   0.08648975193500519,\n",
       "   0.08612971007823944,\n",
       "   0.08628879487514496,\n",
       "   0.08613788336515427,\n",
       "   0.08607922494411469,\n",
       "   0.08598010241985321,\n",
       "   0.08614177256822586,\n",
       "   0.08603205531835556,\n",
       "   0.08660358190536499],\n",
       "  'val_pearson': [0.18869668245315552,\n",
       "   0.21075113117694855,\n",
       "   0.22087334096431732,\n",
       "   0.22412291169166565,\n",
       "   0.22460846602916718,\n",
       "   0.22864587604999542,\n",
       "   0.23298370838165283,\n",
       "   0.22815674543380737,\n",
       "   0.2329552322626114,\n",
       "   0.23252879083156586,\n",
       "   0.2308291643857956,\n",
       "   0.23139993846416473,\n",
       "   0.22727450728416443],\n",
       "  'train_loss': [0.09303208440542221,\n",
       "   0.08726052939891815,\n",
       "   0.08687794953584671,\n",
       "   0.08651027828454971,\n",
       "   0.0862734317779541,\n",
       "   0.08606696128845215,\n",
       "   0.0859711617231369,\n",
       "   0.08591634035110474,\n",
       "   0.08584316074848175,\n",
       "   0.0858207568526268,\n",
       "   0.08580882847309113,\n",
       "   0.08573165535926819,\n",
       "   0.08579297363758087],\n",
       "  'train_pearson': [0.16806641221046448,\n",
       "   0.2091701328754425,\n",
       "   0.21986576914787292,\n",
       "   0.22563032805919647,\n",
       "   0.23219288885593414,\n",
       "   0.23532448709011078,\n",
       "   0.2372501641511917,\n",
       "   0.23872965574264526,\n",
       "   0.23991942405700684,\n",
       "   0.24048008024692535,\n",
       "   0.24135008454322815,\n",
       "   0.24246414005756378,\n",
       "   0.2415492981672287]},\n",
       " 'RBP14': {'test_loss': 0.09900403767824173,\n",
       "  'test_pearson': 0.4172717034816742,\n",
       "  'val_loss': [0.10148046165704727,\n",
       "   0.10203879326581955,\n",
       "   0.10268085449934006,\n",
       "   0.10070890933275223,\n",
       "   0.1026504635810852,\n",
       "   0.09932872653007507,\n",
       "   0.09950530529022217,\n",
       "   0.102687306702137,\n",
       "   0.09941668063402176],\n",
       "  'val_pearson': [0.4029499888420105,\n",
       "   0.41027557849884033,\n",
       "   0.4109956920146942,\n",
       "   0.4176006019115448,\n",
       "   0.4126526415348053,\n",
       "   0.4194784164428711,\n",
       "   0.41672587394714355,\n",
       "   0.4206131398677826,\n",
       "   0.42002537846565247],\n",
       "  'train_loss': [0.12390726804733276,\n",
       "   0.11685247719287872,\n",
       "   0.11616284400224686,\n",
       "   0.1156625896692276,\n",
       "   0.11535666882991791,\n",
       "   0.11525726318359375,\n",
       "   0.11499974876642227,\n",
       "   0.11491433531045914,\n",
       "   0.11488136649131775],\n",
       "  'train_pearson': [0.3682856857776642,\n",
       "   0.4060734808444977,\n",
       "   0.4117603302001953,\n",
       "   0.41465330123901367,\n",
       "   0.41715988516807556,\n",
       "   0.4185737371444702,\n",
       "   0.420355886220932,\n",
       "   0.42115670442581177,\n",
       "   0.4218839704990387]},\n",
       " 'RBP27': {'test_loss': 0.08871878683567047,\n",
       "  'test_pearson': 0.521532416343689,\n",
       "  'val_loss': [0.09369390457868576,\n",
       "   0.08996749669313431,\n",
       "   0.08879121392965317,\n",
       "   0.08860483020544052,\n",
       "   0.08886200934648514,\n",
       "   0.08835044503211975,\n",
       "   0.08813931047916412,\n",
       "   0.08814514428377151,\n",
       "   0.0904419794678688,\n",
       "   0.08884116262197495],\n",
       "  'val_pearson': [0.5043749213218689,\n",
       "   0.5147736072540283,\n",
       "   0.5252787470817566,\n",
       "   0.5251474976539612,\n",
       "   0.52610844373703,\n",
       "   0.5263177752494812,\n",
       "   0.5281764268875122,\n",
       "   0.5280642509460449,\n",
       "   0.5160831809043884,\n",
       "   0.5262690186500549],\n",
       "  'train_loss': [0.09670442342758179,\n",
       "   0.09139294177293777,\n",
       "   0.09001963585615158,\n",
       "   0.08944563567638397,\n",
       "   0.08912795037031174,\n",
       "   0.08896922320127487,\n",
       "   0.08897265791893005,\n",
       "   0.08881641179323196,\n",
       "   0.08867491781711578,\n",
       "   0.08865402638912201],\n",
       "  'train_pearson': [0.4662357568740845,\n",
       "   0.506123423576355,\n",
       "   0.516139030456543,\n",
       "   0.5210331678390503,\n",
       "   0.522921621799469,\n",
       "   0.5242931246757507,\n",
       "   0.5243676900863647,\n",
       "   0.5253857970237732,\n",
       "   0.5262385010719299,\n",
       "   0.5266677737236023]},\n",
       " 'RBP21': {'test_loss': 0.10948479175567627,\n",
       "  'test_pearson': 0.2602817118167877,\n",
       "  'val_loss': [0.11142916232347488,\n",
       "   0.11167443543672562,\n",
       "   0.11183760315179825,\n",
       "   0.11119619011878967,\n",
       "   0.1107150986790657,\n",
       "   0.11042550206184387,\n",
       "   0.10986048728227615,\n",
       "   0.10952658206224442,\n",
       "   0.10948112607002258,\n",
       "   0.11004099249839783,\n",
       "   0.10967268794775009,\n",
       "   0.10960385948419571],\n",
       "  'val_pearson': [0.23571081459522247,\n",
       "   0.23986518383026123,\n",
       "   0.2397059202194214,\n",
       "   0.2398952841758728,\n",
       "   0.2477485090494156,\n",
       "   0.26018261909484863,\n",
       "   0.2630527913570404,\n",
       "   0.2674318552017212,\n",
       "   0.26826992630958557,\n",
       "   0.26688331365585327,\n",
       "   0.264363557100296,\n",
       "   0.2671101689338684],\n",
       "  'train_loss': [0.11822108924388885,\n",
       "   0.11124449968338013,\n",
       "   0.1110985055565834,\n",
       "   0.11097987741231918,\n",
       "   0.11075469106435776,\n",
       "   0.10992293804883957,\n",
       "   0.10954271256923676,\n",
       "   0.1094074621796608,\n",
       "   0.10934153199195862,\n",
       "   0.10931342840194702,\n",
       "   0.10931513458490372,\n",
       "   0.10927540063858032],\n",
       "  'train_pearson': [0.2237316071987152,\n",
       "   0.24628832936286926,\n",
       "   0.24760696291923523,\n",
       "   0.2485770583152771,\n",
       "   0.25144416093826294,\n",
       "   0.2662550210952759,\n",
       "   0.27154281735420227,\n",
       "   0.2734127342700958,\n",
       "   0.2744970917701721,\n",
       "   0.27484917640686035,\n",
       "   0.27532488107681274,\n",
       "   0.27537527680397034]}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RBP24': {'test_loss': 0.08089615404605865,\n",
       "  'test_pearson': 0.6832637190818787,\n",
       "  'val_loss': [0.08317157626152039,\n",
       "   0.08241984993219376,\n",
       "   0.08193130046129227,\n",
       "   0.08119256049394608,\n",
       "   0.08293337374925613,\n",
       "   0.0812111496925354,\n",
       "   0.08114679902791977,\n",
       "   0.08080604672431946,\n",
       "   0.08138562738895416,\n",
       "   0.08040791004896164,\n",
       "   0.08258187025785446,\n",
       "   0.08136650174856186,\n",
       "   0.0813799500465393],\n",
       "  'val_pearson': [0.6751118898391724,\n",
       "   0.6835731863975525,\n",
       "   0.6848306655883789,\n",
       "   0.685966968536377,\n",
       "   0.6843729019165039,\n",
       "   0.684748649597168,\n",
       "   0.6847829818725586,\n",
       "   0.6862730979919434,\n",
       "   0.6848368644714355,\n",
       "   0.688266932964325,\n",
       "   0.6856490969657898,\n",
       "   0.6864133477210999,\n",
       "   0.6874542832374573],\n",
       "  'train_loss': [0.088261179625988,\n",
       "   0.08312206715345383,\n",
       "   0.08211871981620789,\n",
       "   0.08173932135105133,\n",
       "   0.08157342672348022,\n",
       "   0.08160118013620377,\n",
       "   0.08141207695007324,\n",
       "   0.08117301017045975,\n",
       "   0.0811241939663887,\n",
       "   0.0810522735118866,\n",
       "   0.08097200840711594,\n",
       "   0.08100549876689911,\n",
       "   0.08089882135391235],\n",
       "  'train_pearson': [0.6576274037361145,\n",
       "   0.6793257594108582,\n",
       "   0.6838172674179077,\n",
       "   0.6854066848754883,\n",
       "   0.6863070130348206,\n",
       "   0.6868412494659424,\n",
       "   0.6874854564666748,\n",
       "   0.6880630850791931,\n",
       "   0.6885907649993896,\n",
       "   0.6888324618339539,\n",
       "   0.6890060305595398,\n",
       "   0.6888905167579651,\n",
       "   0.6890208125114441]},\n",
       " 'RBP31': {'test_loss': 0.07962143421173096,\n",
       "  'test_pearson': 0.5043666362762451,\n",
       "  'val_loss': [0.0816999301314354,\n",
       "   0.08040738105773926,\n",
       "   0.08017322421073914,\n",
       "   0.08100143074989319,\n",
       "   0.08058805018663406,\n",
       "   0.07966804504394531,\n",
       "   0.08138211071491241,\n",
       "   0.08059684187173843,\n",
       "   0.07987185567617416],\n",
       "  'val_pearson': [0.49744486808776855,\n",
       "   0.5056229829788208,\n",
       "   0.5063547492027283,\n",
       "   0.5098357796669006,\n",
       "   0.5108951926231384,\n",
       "   0.5111981630325317,\n",
       "   0.5091492533683777,\n",
       "   0.5079281330108643,\n",
       "   0.5101898908615112],\n",
       "  'train_loss': [0.08687647432088852,\n",
       "   0.0811508372426033,\n",
       "   0.08061888813972473,\n",
       "   0.08033175021409988,\n",
       "   0.08016400784254074,\n",
       "   0.0800725594162941,\n",
       "   0.07992754876613617,\n",
       "   0.07981187105178833,\n",
       "   0.07975286990404129],\n",
       "  'train_pearson': [0.4720739424228668,\n",
       "   0.5019441843032837,\n",
       "   0.5058638453483582,\n",
       "   0.507787823677063,\n",
       "   0.5090113878250122,\n",
       "   0.5102007389068604,\n",
       "   0.5114094614982605,\n",
       "   0.5120881199836731,\n",
       "   0.5130082368850708]},\n",
       " 'RBP29': {'test_loss': 0.12028158456087112,\n",
       "  'test_pearson': 0.2486068606376648,\n",
       "  'val_loss': [0.12158841639757156,\n",
       "   0.12072927504777908,\n",
       "   0.12028595060110092,\n",
       "   0.12037944048643112,\n",
       "   0.11999467760324478,\n",
       "   0.12025734037160873,\n",
       "   0.12030851095914841,\n",
       "   0.12147565186023712],\n",
       "  'val_pearson': [0.232627734541893,\n",
       "   0.2560873031616211,\n",
       "   0.2562190592288971,\n",
       "   0.2549457848072052,\n",
       "   0.2583306133747101,\n",
       "   0.25425592064857483,\n",
       "   0.25665754079818726,\n",
       "   0.25692686438560486],\n",
       "  'train_loss': [0.12633556127548218,\n",
       "   0.1209697350859642,\n",
       "   0.12039008736610413,\n",
       "   0.12036372721195221,\n",
       "   0.12034676969051361,\n",
       "   0.12029191851615906,\n",
       "   0.12024573236703873,\n",
       "   0.1201845183968544],\n",
       "  'train_pearson': [0.2202281802892685,\n",
       "   0.25056785345077515,\n",
       "   0.257625937461853,\n",
       "   0.2581092119216919,\n",
       "   0.257904052734375,\n",
       "   0.25878164172172546,\n",
       "   0.259570837020874,\n",
       "   0.26008546352386475]},\n",
       " 'RBP35': {'test_loss': 0.11677354574203491,\n",
       "  'test_pearson': 0.19548960030078888,\n",
       "  'val_loss': [0.11722345650196075,\n",
       "   0.11662062257528305,\n",
       "   0.11665951460599899,\n",
       "   0.11697469651699066,\n",
       "   0.11667178571224213],\n",
       "  'val_pearson': [0.2046707719564438,\n",
       "   0.20325545966625214,\n",
       "   0.2042185366153717,\n",
       "   0.2030118703842163,\n",
       "   0.20374096930027008],\n",
       "  'train_loss': [0.11899714916944504,\n",
       "   0.1168273314833641,\n",
       "   0.11679612100124359,\n",
       "   0.11678339540958405,\n",
       "   0.11677839607000351],\n",
       "  'train_pearson': [nan,\n",
       "   0.2036081999540329,\n",
       "   0.20372171700000763,\n",
       "   0.20398758351802826,\n",
       "   0.2040649652481079]},\n",
       " 'RBP22': {'test_loss': 0.101685531437397,\n",
       "  'test_pearson': 0.4085964858531952,\n",
       "  'val_loss': [0.10299437493085861,\n",
       "   0.10273316502571106,\n",
       "   0.10196276754140854,\n",
       "   0.10194384306669235,\n",
       "   0.10199791938066483,\n",
       "   0.10193951427936554,\n",
       "   0.10172786563634872,\n",
       "   0.10187742859125137,\n",
       "   0.10179942101240158,\n",
       "   0.10169833153486252,\n",
       "   0.10165581107139587,\n",
       "   0.10180298238992691,\n",
       "   0.10216841101646423,\n",
       "   0.10193102061748505],\n",
       "  'val_pearson': [0.3984992504119873,\n",
       "   0.40118277072906494,\n",
       "   0.4088740646839142,\n",
       "   0.40971869230270386,\n",
       "   0.410365492105484,\n",
       "   0.41067132353782654,\n",
       "   0.41088542342185974,\n",
       "   0.4109882116317749,\n",
       "   0.41168755292892456,\n",
       "   0.41132888197898865,\n",
       "   0.41203057765960693,\n",
       "   0.41049882769584656,\n",
       "   0.4104776680469513,\n",
       "   0.41014495491981506],\n",
       "  'train_loss': [0.11003096401691437,\n",
       "   0.10287018865346909,\n",
       "   0.10244255512952805,\n",
       "   0.10194392502307892,\n",
       "   0.10182216763496399,\n",
       "   0.10172530263662338,\n",
       "   0.10177541524171829,\n",
       "   0.10173530876636505,\n",
       "   0.10171707719564438,\n",
       "   0.10165977478027344,\n",
       "   0.10163348913192749,\n",
       "   0.10163117200136185,\n",
       "   0.10166370868682861,\n",
       "   0.10162008553743362],\n",
       "  'train_pearson': [0.3928428888320923,\n",
       "   0.4050336480140686,\n",
       "   0.4091419577598572,\n",
       "   0.41341012716293335,\n",
       "   0.4144830107688904,\n",
       "   0.4146682620048523,\n",
       "   0.4148578345775604,\n",
       "   0.4151895344257355,\n",
       "   0.41540512442588806,\n",
       "   0.41584038734436035,\n",
       "   0.4157973527908325,\n",
       "   0.4159430265426636,\n",
       "   0.4161185622215271,\n",
       "   0.4159928560256958]},\n",
       " 'RBP7': {'test_loss': 0.08339732885360718,\n",
       "  'test_pearson': 0.3805306851863861,\n",
       "  'val_loss': [0.08536586165428162,\n",
       "   0.08445173501968384,\n",
       "   0.0843365415930748,\n",
       "   0.08322232961654663,\n",
       "   0.08394640684127808,\n",
       "   0.08336091786623001,\n",
       "   0.08396372199058533],\n",
       "  'val_pearson': [0.3640698194503784,\n",
       "   0.379184752702713,\n",
       "   0.3840065002441406,\n",
       "   0.39067062735557556,\n",
       "   0.3905212879180908,\n",
       "   0.3893697261810303,\n",
       "   0.39052116870880127],\n",
       "  'train_loss': [0.09612561017274857,\n",
       "   0.0850755125284195,\n",
       "   0.08420451730489731,\n",
       "   0.08376375585794449,\n",
       "   0.08357208967208862,\n",
       "   0.08343412727117538,\n",
       "   0.08326998353004456],\n",
       "  'train_pearson': [0.3002333641052246,\n",
       "   0.3713543117046356,\n",
       "   0.3815510869026184,\n",
       "   0.38704970479011536,\n",
       "   0.3899953365325928,\n",
       "   0.39171987771987915,\n",
       "   0.3937028646469116]},\n",
       " 'RBP3': {'test_loss': 0.08778701722621918,\n",
       "  'test_pearson': 0.5360462069511414,\n",
       "  'val_loss': [0.08966847509145737,\n",
       "   0.08889325708150864,\n",
       "   0.08889499306678772,\n",
       "   0.08776216953992844,\n",
       "   0.08921767771244049,\n",
       "   0.08788443356752396,\n",
       "   0.0878991186618805],\n",
       "  'val_pearson': [0.5254905223846436,\n",
       "   0.5352314114570618,\n",
       "   0.5371983051300049,\n",
       "   0.5385974049568176,\n",
       "   0.5405755043029785,\n",
       "   0.5400220155715942,\n",
       "   0.5400159955024719],\n",
       "  'train_loss': [0.09497115761041641,\n",
       "   0.08983051776885986,\n",
       "   0.08925402164459229,\n",
       "   0.08891705423593521,\n",
       "   0.08861041069030762,\n",
       "   0.08846352249383926,\n",
       "   0.08838698267936707],\n",
       "  'train_pearson': [0.5006524920463562,\n",
       "   0.5272312760353088,\n",
       "   0.5315695405006409,\n",
       "   0.5342238545417786,\n",
       "   0.536231517791748,\n",
       "   0.5377413034439087,\n",
       "   0.5380210280418396]},\n",
       " 'RBP32': {'test_loss': 0.07927266508340836,\n",
       "  'test_pearson': 0.5078359842300415,\n",
       "  'val_loss': [0.08228293806314468,\n",
       "   0.08020070195198059,\n",
       "   0.07999853789806366,\n",
       "   0.08038375526666641,\n",
       "   0.07964091747999191,\n",
       "   0.07987639307975769,\n",
       "   0.07955899834632874,\n",
       "   0.07975684851408005,\n",
       "   0.07967626303434372,\n",
       "   0.07951992005109787,\n",
       "   0.07934920489788055,\n",
       "   0.07944770157337189,\n",
       "   0.08047487586736679,\n",
       "   0.07955384999513626],\n",
       "  'val_pearson': [0.4861387312412262,\n",
       "   0.5056171417236328,\n",
       "   0.5083848237991333,\n",
       "   0.5072170495986938,\n",
       "   0.5111494660377502,\n",
       "   0.5113295912742615,\n",
       "   0.5113665461540222,\n",
       "   0.5103336572647095,\n",
       "   0.5125412940979004,\n",
       "   0.5134623050689697,\n",
       "   0.5144534111022949,\n",
       "   0.5134184956550598,\n",
       "   0.5131129026412964,\n",
       "   0.5147085785865784],\n",
       "  'train_loss': [0.08900732547044754,\n",
       "   0.0811741054058075,\n",
       "   0.08050057291984558,\n",
       "   0.08025309443473816,\n",
       "   0.07997747510671616,\n",
       "   0.07984902709722519,\n",
       "   0.07969895005226135,\n",
       "   0.07966740429401398,\n",
       "   0.07958126813173294,\n",
       "   0.07955782860517502,\n",
       "   0.07951865345239639,\n",
       "   0.07954723387956619,\n",
       "   0.07945358753204346,\n",
       "   0.07951442897319794],\n",
       "  'train_pearson': [0.45030224323272705,\n",
       "   0.5004310011863708,\n",
       "   0.5069504976272583,\n",
       "   0.509112536907196,\n",
       "   0.5105326771736145,\n",
       "   0.5117560029029846,\n",
       "   0.5129448771476746,\n",
       "   0.5135356187820435,\n",
       "   0.5139682292938232,\n",
       "   0.514754056930542,\n",
       "   0.5149791836738586,\n",
       "   0.5149048566818237,\n",
       "   0.5152044892311096,\n",
       "   0.5151236653327942]},\n",
       " 'RBP12': {'test_loss': 0.07576292008161545,\n",
       "  'test_pearson': 0.6336047649383545,\n",
       "  'val_loss': [0.07880809158086777,\n",
       "   0.07675007730722427,\n",
       "   0.07781458646059036,\n",
       "   0.07677106559276581,\n",
       "   0.07722534239292145],\n",
       "  'val_pearson': [0.6230922341346741,\n",
       "   0.6269285678863525,\n",
       "   0.6277063488960266,\n",
       "   0.6279991865158081,\n",
       "   0.6280434727668762],\n",
       "  'train_loss': [0.08400306850671768,\n",
       "   0.0770999938249588,\n",
       "   0.07683627307415009,\n",
       "   0.07669716328382492,\n",
       "   0.0766892358660698],\n",
       "  'train_pearson': [0.6086538434028625,\n",
       "   0.627702534198761,\n",
       "   0.629260241985321,\n",
       "   0.6298033595085144,\n",
       "   0.6300708651542664]},\n",
       " 'RBP4': {'test_loss': 0.09292133897542953,\n",
       "  'test_pearson': 0.38053569197654724,\n",
       "  'val_loss': [0.09349595010280609,\n",
       "   0.09452622383832932,\n",
       "   0.09300974011421204,\n",
       "   0.09377194941043854,\n",
       "   0.09291164577007294,\n",
       "   0.09380795061588287,\n",
       "   0.09410452842712402,\n",
       "   0.09307752549648285],\n",
       "  'val_pearson': [0.381272554397583,\n",
       "   0.3842768669128418,\n",
       "   0.38417649269104004,\n",
       "   0.3852311968803406,\n",
       "   0.3850676715373993,\n",
       "   0.38309091329574585,\n",
       "   0.3845895826816559,\n",
       "   0.3850134313106537],\n",
       "  'train_loss': [0.0975947231054306,\n",
       "   0.092969611287117,\n",
       "   0.09280789643526077,\n",
       "   0.09270139038562775,\n",
       "   0.0926942303776741,\n",
       "   0.09267265349626541,\n",
       "   0.0927010253071785,\n",
       "   0.09262792766094208],\n",
       "  'train_pearson': [0.3716636002063751,\n",
       "   0.3877824544906616,\n",
       "   0.3890167474746704,\n",
       "   0.3893669843673706,\n",
       "   0.3898012042045593,\n",
       "   0.3900342285633087,\n",
       "   0.3896941542625427,\n",
       "   0.3898851275444031]},\n",
       " 'RBP30': {'test_loss': 0.12076286226511002,\n",
       "  'test_pearson': 0.24042512476444244,\n",
       "  'val_loss': [0.12428300082683563,\n",
       "   0.12130433320999146,\n",
       "   0.12150608748197556,\n",
       "   0.12101544439792633,\n",
       "   0.12099982798099518,\n",
       "   0.12078416347503662,\n",
       "   0.12092118710279465,\n",
       "   0.12144962698221207,\n",
       "   0.12076772749423981,\n",
       "   0.120498888194561,\n",
       "   0.12063858658075333,\n",
       "   0.12117379158735275,\n",
       "   0.12059302628040314],\n",
       "  'val_pearson': [0.234021857380867,\n",
       "   0.23914577066898346,\n",
       "   0.2399033010005951,\n",
       "   0.24527177214622498,\n",
       "   0.24649854004383087,\n",
       "   0.24501848220825195,\n",
       "   0.24607659876346588,\n",
       "   0.24940672516822815,\n",
       "   0.2472415268421173,\n",
       "   0.2500271201133728,\n",
       "   0.2482561469078064,\n",
       "   0.24742265045642853,\n",
       "   0.2491607666015625],\n",
       "  'train_loss': [0.12602776288986206,\n",
       "   0.12175199389457703,\n",
       "   0.12137558311223984,\n",
       "   0.12123984843492508,\n",
       "   0.12093754857778549,\n",
       "   0.12089034169912338,\n",
       "   0.12083500623703003,\n",
       "   0.12076103687286377,\n",
       "   0.12073899805545807,\n",
       "   0.12077751010656357,\n",
       "   0.1207217201590538,\n",
       "   0.12069274485111237,\n",
       "   0.12068663537502289],\n",
       "  'train_pearson': [0.2198323756456375,\n",
       "   0.23718176782131195,\n",
       "   0.242217019200325,\n",
       "   0.24351324141025543,\n",
       "   0.24631738662719727,\n",
       "   0.24754853546619415,\n",
       "   0.24747972190380096,\n",
       "   0.2489088773727417,\n",
       "   0.2491876482963562,\n",
       "   0.24890029430389404,\n",
       "   0.24927543103694916,\n",
       "   0.24995383620262146,\n",
       "   0.24993020296096802]},\n",
       " 'RBP25': {'test_loss': 0.08407232165336609,\n",
       "  'test_pearson': 0.6029499173164368,\n",
       "  'val_loss': [0.08574546128511429,\n",
       "   0.08580091595649719,\n",
       "   0.0849611684679985,\n",
       "   0.08646351844072342,\n",
       "   0.08491399139165878,\n",
       "   0.08466347306966782,\n",
       "   0.08453256636857986,\n",
       "   0.08453306555747986,\n",
       "   0.08545670658349991,\n",
       "   0.08437708020210266,\n",
       "   0.08443370461463928,\n",
       "   0.08489169925451279,\n",
       "   0.08427480608224869,\n",
       "   0.08482176065444946,\n",
       "   0.08440249413251877,\n",
       "   0.08441954851150513],\n",
       "  'val_pearson': [0.5942342877388,\n",
       "   0.5972652435302734,\n",
       "   0.5990087985992432,\n",
       "   0.6004088521003723,\n",
       "   0.6014673113822937,\n",
       "   0.6024866700172424,\n",
       "   0.6027275919914246,\n",
       "   0.6029482483863831,\n",
       "   0.6025161147117615,\n",
       "   0.6032503247261047,\n",
       "   0.6032525300979614,\n",
       "   0.6035944223403931,\n",
       "   0.6037019491195679,\n",
       "   0.6025092601776123,\n",
       "   0.6033773422241211,\n",
       "   0.6026244759559631],\n",
       "  'train_loss': [0.09258853644132614,\n",
       "   0.08575751632452011,\n",
       "   0.0852968618273735,\n",
       "   0.08495207875967026,\n",
       "   0.0849369689822197,\n",
       "   0.0846746489405632,\n",
       "   0.08468920737504959,\n",
       "   0.08458561450242996,\n",
       "   0.08462224155664444,\n",
       "   0.08451362699270248,\n",
       "   0.08445340394973755,\n",
       "   0.08445635437965393,\n",
       "   0.08435936272144318,\n",
       "   0.08443158864974976,\n",
       "   0.08449872583150864,\n",
       "   0.08440395444631577],\n",
       "  'train_pearson': [0.5755522847175598,\n",
       "   0.5973218679428101,\n",
       "   0.6002378463745117,\n",
       "   0.6016762256622314,\n",
       "   0.6022725105285645,\n",
       "   0.6033328175544739,\n",
       "   0.6037523746490479,\n",
       "   0.6043093800544739,\n",
       "   0.6046555638313293,\n",
       "   0.6048961877822876,\n",
       "   0.604951798915863,\n",
       "   0.6053448915481567,\n",
       "   0.6052659153938293,\n",
       "   0.605492889881134,\n",
       "   0.6054374575614929,\n",
       "   0.6056214570999146]},\n",
       " 'RBP36': {'test_loss': 0.06443966180086136,\n",
       "  'test_pearson': 0.5511786341667175,\n",
       "  'val_loss': [0.0681711956858635,\n",
       "   0.06996931880712509,\n",
       "   0.06711637228727341,\n",
       "   0.06613770872354507,\n",
       "   0.06567970663309097,\n",
       "   0.06499850749969482,\n",
       "   0.06514443457126617,\n",
       "   0.06496141850948334,\n",
       "   0.06481114774942398,\n",
       "   0.06596656888723373,\n",
       "   0.06460961699485779,\n",
       "   0.06488298624753952,\n",
       "   0.06487720459699631,\n",
       "   0.06442239135503769,\n",
       "   0.06503808498382568,\n",
       "   0.06484124809503555,\n",
       "   0.06437712162733078,\n",
       "   0.0644816905260086,\n",
       "   0.06452353298664093,\n",
       "   0.06585711240768433],\n",
       "  'val_pearson': [0.5207117199897766,\n",
       "   0.5240908861160278,\n",
       "   0.5294334292411804,\n",
       "   0.5360229015350342,\n",
       "   0.5426209568977356,\n",
       "   0.5476530194282532,\n",
       "   0.5511997938156128,\n",
       "   0.5481473207473755,\n",
       "   0.5495529174804688,\n",
       "   0.5490321516990662,\n",
       "   0.5513013005256653,\n",
       "   0.5499460697174072,\n",
       "   0.5530146956443787,\n",
       "   0.5531516075134277,\n",
       "   0.5491011142730713,\n",
       "   0.5530009865760803,\n",
       "   0.5536116361618042,\n",
       "   0.5540840029716492,\n",
       "   0.5537805557250977,\n",
       "   0.5525979995727539],\n",
       "  'train_loss': [0.07250957190990448,\n",
       "   0.0676770955324173,\n",
       "   0.06726972758769989,\n",
       "   0.06671376526355743,\n",
       "   0.06607161462306976,\n",
       "   0.06521587073802948,\n",
       "   0.0648408979177475,\n",
       "   0.0647001788020134,\n",
       "   0.0646972730755806,\n",
       "   0.06459588557481766,\n",
       "   0.06456418335437775,\n",
       "   0.0644439160823822,\n",
       "   0.0644695907831192,\n",
       "   0.06441923975944519,\n",
       "   0.06437620520591736,\n",
       "   0.06431441754102707,\n",
       "   0.06425616890192032,\n",
       "   0.0642407163977623,\n",
       "   0.06426677107810974,\n",
       "   0.06418546289205551],\n",
       "  'train_pearson': [0.49828460812568665,\n",
       "   0.5240007042884827,\n",
       "   0.5286530256271362,\n",
       "   0.5334752798080444,\n",
       "   0.5396623015403748,\n",
       "   0.5484110713005066,\n",
       "   0.5522867441177368,\n",
       "   0.5532994866371155,\n",
       "   0.5540052652359009,\n",
       "   0.5544673204421997,\n",
       "   0.5549903512001038,\n",
       "   0.5556296706199646,\n",
       "   0.5559045672416687,\n",
       "   0.556613028049469,\n",
       "   0.5566607713699341,\n",
       "   0.5576525926589966,\n",
       "   0.5576509833335876,\n",
       "   0.5577709674835205,\n",
       "   0.5580723881721497,\n",
       "   0.558485746383667]},\n",
       " 'RBP23': {'test_loss': 0.08327086269855499,\n",
       "  'test_pearson': 0.6722136735916138,\n",
       "  'val_loss': [0.0844302624464035,\n",
       "   0.08480429649353027,\n",
       "   0.0840151309967041,\n",
       "   0.08459635078907013,\n",
       "   0.08397822827100754,\n",
       "   0.08451787382364273,\n",
       "   0.08379652351140976,\n",
       "   0.08339709788560867,\n",
       "   0.08348637819290161,\n",
       "   0.08366101235151291,\n",
       "   0.0836048498749733],\n",
       "  'val_pearson': [0.6688644289970398,\n",
       "   0.6705639958381653,\n",
       "   0.671790361404419,\n",
       "   0.6722902059555054,\n",
       "   0.6715079545974731,\n",
       "   0.673291027545929,\n",
       "   0.6734491586685181,\n",
       "   0.6744787096977234,\n",
       "   0.6752414107322693,\n",
       "   0.6744667291641235,\n",
       "   0.6741279363632202],\n",
       "  'train_loss': [0.09835656732320786,\n",
       "   0.0853920578956604,\n",
       "   0.08464455604553223,\n",
       "   0.08431467413902283,\n",
       "   0.08410321921110153,\n",
       "   0.08392525464296341,\n",
       "   0.08378652483224869,\n",
       "   0.08368274569511414,\n",
       "   0.08367224782705307,\n",
       "   0.08348432928323746,\n",
       "   0.0835612565279007],\n",
       "  'train_pearson': [0.6391844749450684,\n",
       "   0.6686888337135315,\n",
       "   0.6709972023963928,\n",
       "   0.6724194884300232,\n",
       "   0.6740875840187073,\n",
       "   0.6745100021362305,\n",
       "   0.6752091646194458,\n",
       "   0.6755174398422241,\n",
       "   0.6759882569313049,\n",
       "   0.6766852140426636,\n",
       "   0.6767668724060059]},\n",
       " 'RBP13': {'test_loss': 0.08774139732122421,\n",
       "  'test_pearson': 0.47808828949928284,\n",
       "  'val_loss': [0.09246000647544861,\n",
       "   0.09128259867429733,\n",
       "   0.09038957953453064,\n",
       "   0.08997408300638199,\n",
       "   0.08862052112817764,\n",
       "   0.08850137889385223,\n",
       "   0.08822979032993317,\n",
       "   0.08822599798440933,\n",
       "   0.08837171643972397,\n",
       "   0.08894025534391403,\n",
       "   0.08798081427812576,\n",
       "   0.08898700028657913,\n",
       "   0.08861949294805527,\n",
       "   0.08840116113424301],\n",
       "  'val_pearson': [0.4472377598285675,\n",
       "   0.45890334248542786,\n",
       "   0.46181005239486694,\n",
       "   0.463982492685318,\n",
       "   0.4749080240726471,\n",
       "   0.4768297076225281,\n",
       "   0.4789314866065979,\n",
       "   0.48103323578834534,\n",
       "   0.47902384400367737,\n",
       "   0.47441190481185913,\n",
       "   0.48076409101486206,\n",
       "   0.4805452227592468,\n",
       "   0.4782692790031433,\n",
       "   0.4807946979999542],\n",
       "  'train_loss': [0.09768494218587875,\n",
       "   0.09127285331487656,\n",
       "   0.09043675661087036,\n",
       "   0.09007935971021652,\n",
       "   0.0891590341925621,\n",
       "   0.08861616253852844,\n",
       "   0.08838143199682236,\n",
       "   0.08821021765470505,\n",
       "   0.088106170296669,\n",
       "   0.08806014060974121,\n",
       "   0.0878976359963417,\n",
       "   0.08793101459741592,\n",
       "   0.08785592764616013,\n",
       "   0.08781297504901886],\n",
       "  'train_pearson': [0.4235677719116211,\n",
       "   0.4537610411643982,\n",
       "   0.46107399463653564,\n",
       "   0.4644787013530731,\n",
       "   0.47324493527412415,\n",
       "   0.47801294922828674,\n",
       "   0.4802498519420624,\n",
       "   0.48192188143730164,\n",
       "   0.483187735080719,\n",
       "   0.48380953073501587,\n",
       "   0.4845571517944336,\n",
       "   0.48469632863998413,\n",
       "   0.4851393699645996,\n",
       "   0.4856216311454773]},\n",
       " 'RBP6': {'test_loss': 0.08190469443798065,\n",
       "  'test_pearson': 0.22820214927196503,\n",
       "  'val_loss': [0.08311988413333893,\n",
       "   0.08224162459373474,\n",
       "   0.08188416063785553,\n",
       "   0.08344703912734985,\n",
       "   0.08175170421600342,\n",
       "   0.08534892648458481,\n",
       "   0.08332283794879913,\n",
       "   0.08280684798955917],\n",
       "  'val_pearson': [0.2081933319568634,\n",
       "   0.22453060746192932,\n",
       "   0.23195581138134003,\n",
       "   0.22939424216747284,\n",
       "   0.2355508953332901,\n",
       "   0.23597800731658936,\n",
       "   0.233437180519104,\n",
       "   0.2330014556646347],\n",
       "  'train_loss': [0.11117111146450043,\n",
       "   0.08288118243217468,\n",
       "   0.08212830871343613,\n",
       "   0.08200063556432724,\n",
       "   0.0817958414554596,\n",
       "   0.08159888535737991,\n",
       "   0.0816381424665451,\n",
       "   0.08131027221679688],\n",
       "  'train_pearson': [0.13478058576583862,\n",
       "   0.22314955294132233,\n",
       "   0.24058812856674194,\n",
       "   0.24824655055999756,\n",
       "   0.25296083092689514,\n",
       "   0.25621816515922546,\n",
       "   0.25912508368492126,\n",
       "   0.2603493928909302]},\n",
       " 'RBP2': {'test_loss': 0.10636033117771149,\n",
       "  'test_pearson': 0.5985762476921082,\n",
       "  'val_loss': [0.11508626490831375,\n",
       "   0.110965795814991,\n",
       "   0.10914257168769836,\n",
       "   0.10732042789459229,\n",
       "   0.10735355317592621,\n",
       "   0.10692263394594193,\n",
       "   0.10725845396518707,\n",
       "   0.10703965276479721,\n",
       "   0.10715007781982422],\n",
       "  'val_pearson': [0.5658345818519592,\n",
       "   0.5813230872154236,\n",
       "   0.5895354747772217,\n",
       "   0.5944685339927673,\n",
       "   0.5965767502784729,\n",
       "   0.5969215631484985,\n",
       "   0.5982813239097595,\n",
       "   0.6011756062507629,\n",
       "   0.5976694822311401],\n",
       "  'train_loss': [0.12646235525608063,\n",
       "   0.11191345751285553,\n",
       "   0.10945639759302139,\n",
       "   0.10839436948299408,\n",
       "   0.10763059556484222,\n",
       "   0.1069820374250412,\n",
       "   0.1066264882683754,\n",
       "   0.10626038908958435,\n",
       "   0.10615736991167068],\n",
       "  'train_pearson': [0.5320912003517151,\n",
       "   0.5736694931983948,\n",
       "   0.5863757133483887,\n",
       "   0.5918317437171936,\n",
       "   0.5950536131858826,\n",
       "   0.5983719229698181,\n",
       "   0.6004650592803955,\n",
       "   0.6015937328338623,\n",
       "   0.6026566624641418]},\n",
       " 'RBP34': {'test_loss': 0.0744229331612587,\n",
       "  'test_pearson': 0.5402108430862427,\n",
       "  'val_loss': [0.07814887166023254,\n",
       "   0.07622923702001572,\n",
       "   0.07631717622280121,\n",
       "   0.07560327649116516,\n",
       "   0.07544829696416855,\n",
       "   0.0752192959189415,\n",
       "   0.07581710815429688,\n",
       "   0.07487387210130692,\n",
       "   0.07507532835006714,\n",
       "   0.07743997126817703,\n",
       "   0.07539232820272446],\n",
       "  'val_pearson': [0.5141202807426453,\n",
       "   0.5312586426734924,\n",
       "   0.5372205376625061,\n",
       "   0.5381970405578613,\n",
       "   0.5392173528671265,\n",
       "   0.5393306016921997,\n",
       "   0.5401663184165955,\n",
       "   0.5425314903259277,\n",
       "   0.5417617559432983,\n",
       "   0.5404277443885803,\n",
       "   0.542174756526947],\n",
       "  'train_loss': [0.08651397377252579,\n",
       "   0.07714392244815826,\n",
       "   0.0761316567659378,\n",
       "   0.07565762847661972,\n",
       "   0.07558156549930573,\n",
       "   0.07535648345947266,\n",
       "   0.07520166784524918,\n",
       "   0.07519765943288803,\n",
       "   0.0751308724284172,\n",
       "   0.0750926211476326,\n",
       "   0.07501291483640671],\n",
       "  'train_pearson': [nan,\n",
       "   0.5254301428794861,\n",
       "   0.5351241827011108,\n",
       "   0.5379436612129211,\n",
       "   0.5399537086486816,\n",
       "   0.5415714383125305,\n",
       "   0.5423320531845093,\n",
       "   0.5432641506195068,\n",
       "   0.5441092848777771,\n",
       "   0.5442682504653931,\n",
       "   0.5445697903633118]},\n",
       " 'RBP19': {'test_loss': 0.08712582290172577,\n",
       "  'test_pearson': 0.6394930481910706,\n",
       "  'val_loss': [0.08990705758333206,\n",
       "   0.09005378931760788,\n",
       "   0.09020281583070755,\n",
       "   0.08977040648460388,\n",
       "   0.08982738852500916,\n",
       "   0.09021875262260437,\n",
       "   0.08861564844846725,\n",
       "   0.08859635889530182,\n",
       "   0.09049730002880096,\n",
       "   0.08826316148042679,\n",
       "   0.0902378186583519,\n",
       "   0.08796118944883347,\n",
       "   0.08899220824241638,\n",
       "   0.08912064880132675,\n",
       "   0.08901278674602509],\n",
       "  'val_pearson': [0.6259573101997375,\n",
       "   0.6302027702331543,\n",
       "   0.6337729692459106,\n",
       "   0.632927417755127,\n",
       "   0.6335049271583557,\n",
       "   0.6245417594909668,\n",
       "   0.6347787380218506,\n",
       "   0.636191189289093,\n",
       "   0.6355219483375549,\n",
       "   0.6348644495010376,\n",
       "   0.6360079050064087,\n",
       "   0.635980486869812,\n",
       "   0.6346529722213745,\n",
       "   0.6318886280059814,\n",
       "   0.6362825036048889],\n",
       "  'train_loss': [0.09465784579515457,\n",
       "   0.08951286226511002,\n",
       "   0.08883780241012573,\n",
       "   0.08808387815952301,\n",
       "   0.08784523606300354,\n",
       "   0.0878630056977272,\n",
       "   0.0876026451587677,\n",
       "   0.08750106394290924,\n",
       "   0.0872933566570282,\n",
       "   0.08720874041318893,\n",
       "   0.0870579406619072,\n",
       "   0.08726118505001068,\n",
       "   0.0872439444065094,\n",
       "   0.08704674988985062,\n",
       "   0.0869913175702095],\n",
       "  'train_pearson': [0.6117591857910156,\n",
       "   0.6317223310470581,\n",
       "   0.6351613402366638,\n",
       "   0.6386220455169678,\n",
       "   0.6396633982658386,\n",
       "   0.6402090787887573,\n",
       "   0.6415373682975769,\n",
       "   0.6419680714607239,\n",
       "   0.6428335309028625,\n",
       "   0.6430248618125916,\n",
       "   0.6433507204055786,\n",
       "   0.6435567140579224,\n",
       "   0.6435360312461853,\n",
       "   0.643850564956665,\n",
       "   0.6438933610916138]},\n",
       " 'RBP8': {'test_loss': 0.0948973000049591,\n",
       "  'test_pearson': 0.1989498734474182,\n",
       "  'val_loss': [0.09608349949121475,\n",
       "   0.09466858208179474,\n",
       "   0.09496375173330307,\n",
       "   0.09493391215801239,\n",
       "   0.09500639885663986],\n",
       "  'val_pearson': [0.21084442734718323,\n",
       "   0.21333524584770203,\n",
       "   0.2123110443353653,\n",
       "   0.21107545495033264,\n",
       "   0.20511895418167114],\n",
       "  'train_loss': [0.09926352649927139,\n",
       "   0.09512355923652649,\n",
       "   0.0950223058462143,\n",
       "   0.09498341381549835,\n",
       "   0.09498012065887451],\n",
       "  'train_pearson': [0.1880163997411728,\n",
       "   0.2091505378484726,\n",
       "   0.2097243219614029,\n",
       "   0.2100047618150711,\n",
       "   0.20995572209358215]},\n",
       " 'RBP1': {'test_loss': 0.07741265743970871,\n",
       "  'test_pearson': 0.6326812505722046,\n",
       "  'val_loss': [0.07844938337802887,\n",
       "   0.07852959632873535,\n",
       "   0.07765872031450272,\n",
       "   0.07828433811664581,\n",
       "   0.07823017984628677,\n",
       "   0.07837750762701035],\n",
       "  'val_pearson': [0.627009391784668,\n",
       "   0.6294637322425842,\n",
       "   0.6320820450782776,\n",
       "   0.630588948726654,\n",
       "   0.6323758959770203,\n",
       "   0.6283031702041626],\n",
       "  'train_loss': [0.0833977609872818,\n",
       "   0.0790308341383934,\n",
       "   0.07853706926107407,\n",
       "   0.07827096432447433,\n",
       "   0.07820778340101242,\n",
       "   0.07816363871097565],\n",
       "  'train_pearson': [0.6023939251899719,\n",
       "   0.6271832585334778,\n",
       "   0.6302059292793274,\n",
       "   0.6315488219261169,\n",
       "   0.6317812204360962,\n",
       "   0.6321118474006653]},\n",
       " 'RBP16': {'test_loss': 0.10470584779977798,\n",
       "  'test_pearson': 0.5145425796508789,\n",
       "  'val_loss': [0.10490822792053223,\n",
       "   0.10469099134206772,\n",
       "   0.1042569950222969,\n",
       "   0.10435562580823898,\n",
       "   0.10373280197381973,\n",
       "   0.1046241968870163,\n",
       "   0.10374179482460022,\n",
       "   0.10404054075479507],\n",
       "  'val_pearson': [0.5173009634017944,\n",
       "   0.5189010500907898,\n",
       "   0.5220175385475159,\n",
       "   0.5218850374221802,\n",
       "   0.5247003436088562,\n",
       "   0.5241579413414001,\n",
       "   0.5244630575180054,\n",
       "   0.5257675647735596],\n",
       "  'train_loss': [0.11803208291530609,\n",
       "   0.1057124212384224,\n",
       "   0.10516470670700073,\n",
       "   0.10492604970932007,\n",
       "   0.10481603443622589,\n",
       "   0.1046069860458374,\n",
       "   0.10445985198020935,\n",
       "   0.10438748449087143],\n",
       "  'train_pearson': [nan,\n",
       "   0.5143168568611145,\n",
       "   0.5175513029098511,\n",
       "   0.5192197561264038,\n",
       "   0.5201616883277893,\n",
       "   0.5215632915496826,\n",
       "   0.5222883820533752,\n",
       "   0.5227907299995422]},\n",
       " 'RBP5': {'test_loss': 0.06343109160661697,\n",
       "  'test_pearson': 0.2697131335735321,\n",
       "  'val_loss': [0.063988097012043,\n",
       "   0.06358394026756287,\n",
       "   0.063845194876194,\n",
       "   0.0638711228966713,\n",
       "   0.06405451148748398],\n",
       "  'val_pearson': [0.2799099385738373,\n",
       "   0.28411945700645447,\n",
       "   0.28399813175201416,\n",
       "   0.2814107835292816,\n",
       "   0.2803051769733429],\n",
       "  'train_loss': [0.06823280453681946,\n",
       "   0.06411764025688171,\n",
       "   0.06405040621757507,\n",
       "   0.0639820247888565,\n",
       "   0.06387363374233246],\n",
       "  'train_pearson': [0.26998865604400635,\n",
       "   0.28321781754493713,\n",
       "   0.28352662920951843,\n",
       "   0.2839987277984619,\n",
       "   0.28509846329689026]},\n",
       " 'RBP17': {'test_loss': 0.07176375389099121,\n",
       "  'test_pearson': 0.48035678267478943,\n",
       "  'val_loss': [0.07365526258945465,\n",
       "   0.07287575304508209,\n",
       "   0.07225517183542252,\n",
       "   0.07222756743431091,\n",
       "   0.07187313586473465,\n",
       "   0.07225950062274933,\n",
       "   0.07183166593313217,\n",
       "   0.07318103313446045,\n",
       "   0.07158669829368591,\n",
       "   0.07500263303518295,\n",
       "   0.07181217521429062,\n",
       "   0.07264561951160431],\n",
       "  'val_pearson': [0.4735231101512909,\n",
       "   0.47865521907806396,\n",
       "   0.4818052351474762,\n",
       "   0.48137167096138,\n",
       "   0.48478806018829346,\n",
       "   0.4849981963634491,\n",
       "   0.4855951964855194,\n",
       "   0.4853215515613556,\n",
       "   0.48701414465904236,\n",
       "   0.4852254092693329,\n",
       "   0.4846256673336029,\n",
       "   0.485233336687088],\n",
       "  'train_loss': [0.0853683352470398,\n",
       "   0.07902899384498596,\n",
       "   0.0782095417380333,\n",
       "   0.07802856713533401,\n",
       "   0.07775204628705978,\n",
       "   0.0776849165558815,\n",
       "   0.07772195339202881,\n",
       "   0.07760820537805557,\n",
       "   0.07746648788452148,\n",
       "   0.07740295678377151,\n",
       "   0.077429860830307,\n",
       "   0.07729079574346542],\n",
       "  'train_pearson': [0.46120336651802063,\n",
       "   0.4810689687728882,\n",
       "   0.48638391494750977,\n",
       "   0.4882242977619171,\n",
       "   0.4901256561279297,\n",
       "   0.49126508831977844,\n",
       "   0.49170297384262085,\n",
       "   0.4921663701534271,\n",
       "   0.49307000637054443,\n",
       "   0.49324318766593933,\n",
       "   0.4936355650424957,\n",
       "   0.4940647780895233]},\n",
       " 'RBP11': {'test_loss': 0.07586684823036194,\n",
       "  'test_pearson': 0.6323387622833252,\n",
       "  'val_loss': [0.07832533866167068,\n",
       "   0.07693929970264435,\n",
       "   0.07691370695829391,\n",
       "   0.07780542969703674,\n",
       "   0.07722644507884979,\n",
       "   0.07679141312837601,\n",
       "   0.07685448229312897,\n",
       "   0.07699336111545563,\n",
       "   0.0768766775727272],\n",
       "  'val_pearson': [0.6164164543151855,\n",
       "   0.6250435709953308,\n",
       "   0.6255857348442078,\n",
       "   0.625420093536377,\n",
       "   0.6262183785438538,\n",
       "   0.6261468529701233,\n",
       "   0.6262697577476501,\n",
       "   0.6251352429389954,\n",
       "   0.6259194016456604],\n",
       "  'train_loss': [0.08638360351324081,\n",
       "   0.07796361297369003,\n",
       "   0.07700851559638977,\n",
       "   0.0768817737698555,\n",
       "   0.07685375213623047,\n",
       "   0.07677678018808365,\n",
       "   0.07675287127494812,\n",
       "   0.07674635201692581,\n",
       "   0.07676830887794495],\n",
       "  'train_pearson': [0.6026654839515686,\n",
       "   0.6214316487312317,\n",
       "   0.6273431777954102,\n",
       "   0.6279650926589966,\n",
       "   0.6282874941825867,\n",
       "   0.628510057926178,\n",
       "   0.6285431981086731,\n",
       "   0.628688633441925,\n",
       "   0.6289054155349731]},\n",
       " 'RBP33': {'test_loss': 0.07321241497993469,\n",
       "  'test_pearson': 0.5513588786125183,\n",
       "  'val_loss': [0.07573734223842621,\n",
       "   0.07554112374782562,\n",
       "   0.07596927136182785,\n",
       "   0.07534582167863846,\n",
       "   0.0741904154419899,\n",
       "   0.07399880886077881,\n",
       "   0.07538694888353348,\n",
       "   0.0735277608036995,\n",
       "   0.07369404286146164,\n",
       "   0.0757238119840622,\n",
       "   0.07371021807193756],\n",
       "  'val_pearson': [0.5406445264816284,\n",
       "   0.5437743067741394,\n",
       "   0.5466216802597046,\n",
       "   0.5535217523574829,\n",
       "   0.5534639358520508,\n",
       "   0.5547972321510315,\n",
       "   0.5453206300735474,\n",
       "   0.5542968511581421,\n",
       "   0.5556622743606567,\n",
       "   0.5536572337150574,\n",
       "   0.5543041825294495],\n",
       "  'train_loss': [0.07801195234060287,\n",
       "   0.0752701386809349,\n",
       "   0.07482017576694489,\n",
       "   0.07429260015487671,\n",
       "   0.07400939613580704,\n",
       "   0.0738435760140419,\n",
       "   0.07378074526786804,\n",
       "   0.0737777054309845,\n",
       "   0.07373025268316269,\n",
       "   0.07366010546684265,\n",
       "   0.07366343587636948],\n",
       "  'train_pearson': [0.5212426781654358,\n",
       "   0.5433595776557922,\n",
       "   0.5468969345092773,\n",
       "   0.5510182976722717,\n",
       "   0.5534436702728271,\n",
       "   0.5544779896736145,\n",
       "   0.555785596370697,\n",
       "   0.5557816624641418,\n",
       "   0.5561403036117554,\n",
       "   0.556602954864502,\n",
       "   0.5564265251159668]},\n",
       " 'RBP9': {'test_loss': 0.09641962498426437,\n",
       "  'test_pearson': 0.4427846670150757,\n",
       "  'val_loss': [0.09756392985582352,\n",
       "   0.09707477688789368,\n",
       "   0.09764540195465088,\n",
       "   0.097190260887146,\n",
       "   0.09652885794639587,\n",
       "   0.09711983054876328,\n",
       "   0.09596380591392517,\n",
       "   0.09653352200984955,\n",
       "   0.09730423241853714,\n",
       "   0.0975269302725792],\n",
       "  'val_pearson': [0.4373069107532501,\n",
       "   0.4412165582180023,\n",
       "   0.4405304491519928,\n",
       "   0.4493301510810852,\n",
       "   0.44818153977394104,\n",
       "   0.45021042227745056,\n",
       "   0.4518382251262665,\n",
       "   0.45004895329475403,\n",
       "   0.4473184049129486,\n",
       "   0.4496594965457916],\n",
       "  'train_loss': [0.10341722518205643,\n",
       "   0.09847463667392731,\n",
       "   0.09797333180904388,\n",
       "   0.09754234552383423,\n",
       "   0.09736838191747665,\n",
       "   0.09719337522983551,\n",
       "   0.09708739072084427,\n",
       "   0.0970764309167862,\n",
       "   0.09692008793354034,\n",
       "   0.09692400693893433],\n",
       "  'train_pearson': [0.41387414932250977,\n",
       "   0.430583655834198,\n",
       "   0.435313880443573,\n",
       "   0.4391428828239441,\n",
       "   0.4411426782608032,\n",
       "   0.44214382767677307,\n",
       "   0.44314050674438477,\n",
       "   0.44338610768318176,\n",
       "   0.44431057572364807,\n",
       "   0.44487616419792175]},\n",
       " 'RBP20': {'test_loss': 0.10968053340911865,\n",
       "  'test_pearson': 0.2589189410209656,\n",
       "  'val_loss': [0.1120779812335968,\n",
       "   0.11119481176137924,\n",
       "   0.11129943281412125,\n",
       "   0.11162347346544266,\n",
       "   0.11066970229148865,\n",
       "   0.11041871458292007,\n",
       "   0.11027737706899643,\n",
       "   0.11033550649881363,\n",
       "   0.11024308204650879,\n",
       "   0.11024237424135208,\n",
       "   0.11005835235118866,\n",
       "   0.11027226597070694,\n",
       "   0.10985543578863144,\n",
       "   0.11049585789442062,\n",
       "   0.10992886871099472,\n",
       "   0.11020396649837494],\n",
       "  'val_pearson': [0.2365214079618454,\n",
       "   0.2403094470500946,\n",
       "   0.2370806187391281,\n",
       "   0.23682667315006256,\n",
       "   0.250180184841156,\n",
       "   0.25469717383384705,\n",
       "   0.2550849914550781,\n",
       "   0.25408825278282166,\n",
       "   0.25655820965766907,\n",
       "   0.25726911425590515,\n",
       "   0.2590498626232147,\n",
       "   0.2623435854911804,\n",
       "   0.2629622220993042,\n",
       "   0.2649703621864319,\n",
       "   0.26553067564964294,\n",
       "   0.2587491571903229],\n",
       "  'train_loss': [0.11563263088464737,\n",
       "   0.11133828014135361,\n",
       "   0.11116133630275726,\n",
       "   0.11099828034639359,\n",
       "   0.11074837297201157,\n",
       "   0.11026135832071304,\n",
       "   0.11011654138565063,\n",
       "   0.11005993187427521,\n",
       "   0.10998526215553284,\n",
       "   0.10988005250692368,\n",
       "   0.1097380593419075,\n",
       "   0.1095963716506958,\n",
       "   0.10953447222709656,\n",
       "   0.10944750159978867,\n",
       "   0.10945966839790344,\n",
       "   0.10934966802597046],\n",
       "  'train_pearson': [0.223457470536232,\n",
       "   0.24413645267486572,\n",
       "   0.24656854569911957,\n",
       "   0.24781478941440582,\n",
       "   0.2522967457771301,\n",
       "   0.26004722714424133,\n",
       "   0.2618234157562256,\n",
       "   0.26290032267570496,\n",
       "   0.26329413056373596,\n",
       "   0.2643611431121826,\n",
       "   0.26720309257507324,\n",
       "   0.26938167214393616,\n",
       "   0.27058297395706177,\n",
       "   0.2722955644130707,\n",
       "   0.2722494304180145,\n",
       "   0.2728217840194702]},\n",
       " 'RBP10': {'test_loss': 0.10861218720674515,\n",
       "  'test_pearson': 0.43799248337745667,\n",
       "  'val_loss': [0.10943745821714401,\n",
       "   0.10860653966665268,\n",
       "   0.10831589251756668,\n",
       "   0.10819137096405029,\n",
       "   0.10875510424375534,\n",
       "   0.10799803584814072,\n",
       "   0.10792037844657898,\n",
       "   0.10935164988040924,\n",
       "   0.10823853313922882,\n",
       "   0.10899362713098526],\n",
       "  'val_pearson': [0.4327338933944702,\n",
       "   0.4387529492378235,\n",
       "   0.44151967763900757,\n",
       "   0.44264471530914307,\n",
       "   0.44605231285095215,\n",
       "   0.4463612735271454,\n",
       "   0.4447503387928009,\n",
       "   0.44642823934555054,\n",
       "   0.4439992308616638,\n",
       "   0.44520795345306396],\n",
       "  'train_loss': [0.11761781573295593,\n",
       "   0.1100771427154541,\n",
       "   0.10936205834150314,\n",
       "   0.1090635284781456,\n",
       "   0.10896162688732147,\n",
       "   0.10880086570978165,\n",
       "   0.10869169235229492,\n",
       "   0.10857243090867996,\n",
       "   0.10844096541404724,\n",
       "   0.10843163728713989],\n",
       "  'train_pearson': [0.3929128050804138,\n",
       "   0.43108972907066345,\n",
       "   0.4367559254169464,\n",
       "   0.4390670657157898,\n",
       "   0.44027894735336304,\n",
       "   0.44165730476379395,\n",
       "   0.4425261318683624,\n",
       "   0.44348105788230896,\n",
       "   0.44428950548171997,\n",
       "   0.44446009397506714]},\n",
       " 'RBP26': {'test_loss': 0.08237765729427338,\n",
       "  'test_pearson': 0.6139443516731262,\n",
       "  'val_loss': [0.08404985815286636,\n",
       "   0.08328351378440857,\n",
       "   0.08454407006502151,\n",
       "   0.08446551114320755,\n",
       "   0.08298712223768234,\n",
       "   0.08559579402208328,\n",
       "   0.08318331092596054,\n",
       "   0.08280138671398163,\n",
       "   0.08427746593952179,\n",
       "   0.08245796710252762,\n",
       "   0.08247368037700653,\n",
       "   0.08436328917741776,\n",
       "   0.08328959345817566],\n",
       "  'val_pearson': [0.6051102876663208,\n",
       "   0.6106023788452148,\n",
       "   0.6121408939361572,\n",
       "   0.6136922240257263,\n",
       "   0.6134799122810364,\n",
       "   0.6137185096740723,\n",
       "   0.6105935573577881,\n",
       "   0.6136823892593384,\n",
       "   0.6097050309181213,\n",
       "   0.6154541373252869,\n",
       "   0.6146989464759827,\n",
       "   0.6106288433074951,\n",
       "   0.614900529384613],\n",
       "  'train_loss': [0.09195155650377274,\n",
       "   0.08399058878421783,\n",
       "   0.08352243155241013,\n",
       "   0.08319137990474701,\n",
       "   0.08310435712337494,\n",
       "   0.08302134275436401,\n",
       "   0.08306799829006195,\n",
       "   0.08290397375822067,\n",
       "   0.08292271941900253,\n",
       "   0.08273190259933472,\n",
       "   0.08261561393737793,\n",
       "   0.08257059752941132,\n",
       "   0.08248468488454819],\n",
       "  'train_pearson': [0.5809151530265808,\n",
       "   0.6085993051528931,\n",
       "   0.6119498014450073,\n",
       "   0.6133875846862793,\n",
       "   0.6138975024223328,\n",
       "   0.6147103309631348,\n",
       "   0.6150841116905212,\n",
       "   0.6152061223983765,\n",
       "   0.6152777075767517,\n",
       "   0.6161593794822693,\n",
       "   0.6166486740112305,\n",
       "   0.6168491840362549,\n",
       "   0.6167949438095093]},\n",
       " 'RBP18': {'test_loss': 0.10073030740022659,\n",
       "  'test_pearson': 0.5254213213920593,\n",
       "  'val_loss': [0.1069590225815773,\n",
       "   0.10338874906301498,\n",
       "   0.10269564390182495,\n",
       "   0.10182558745145798,\n",
       "   0.10155890882015228,\n",
       "   0.10157796740531921,\n",
       "   0.10092592984437943,\n",
       "   0.10180177539587021,\n",
       "   0.10065662860870361,\n",
       "   0.1006695032119751,\n",
       "   0.10141684859991074,\n",
       "   0.10088348388671875],\n",
       "  'val_pearson': [0.508747935295105,\n",
       "   0.5162025690078735,\n",
       "   0.5245346426963806,\n",
       "   0.5275390148162842,\n",
       "   0.5252565145492554,\n",
       "   0.528287410736084,\n",
       "   0.5284502506256104,\n",
       "   0.5281317234039307,\n",
       "   0.5284181237220764,\n",
       "   0.5286592245101929,\n",
       "   0.5283406376838684,\n",
       "   0.5306769609451294],\n",
       "  'train_loss': [0.11214963346719742,\n",
       "   0.10285302251577377,\n",
       "   0.10170847177505493,\n",
       "   0.10127539187669754,\n",
       "   0.10106078535318375,\n",
       "   0.10088632255792618,\n",
       "   0.10078278183937073,\n",
       "   0.10077711194753647,\n",
       "   0.10060086101293564,\n",
       "   0.10059258341789246,\n",
       "   0.10057823359966278,\n",
       "   0.10049410164356232],\n",
       "  'train_pearson': [0.49109548330307007,\n",
       "   0.5185122489929199,\n",
       "   0.5253446102142334,\n",
       "   0.528645932674408,\n",
       "   0.529980480670929,\n",
       "   0.5308806300163269,\n",
       "   0.5314425230026245,\n",
       "   0.5313618779182434,\n",
       "   0.5317911505699158,\n",
       "   0.5318838953971863,\n",
       "   0.5323341488838196,\n",
       "   0.5329660773277283]},\n",
       " 'RBP28': {'test_loss': 0.10984448343515396,\n",
       "  'test_pearson': 0.4887467920780182,\n",
       "  'val_loss': [0.11467229574918747,\n",
       "   0.11546619981527328,\n",
       "   0.1141207292675972,\n",
       "   0.11193783581256866,\n",
       "   0.11205326020717621,\n",
       "   0.11075866222381592,\n",
       "   0.11253975331783295,\n",
       "   0.10924548655748367,\n",
       "   0.10983628034591675,\n",
       "   0.10941813141107559,\n",
       "   0.11038673669099808],\n",
       "  'val_pearson': [0.45535001158714294,\n",
       "   0.4649590253829956,\n",
       "   0.4696829915046692,\n",
       "   0.47751709818840027,\n",
       "   0.48547887802124023,\n",
       "   0.48864448070526123,\n",
       "   0.484628289937973,\n",
       "   0.4957655072212219,\n",
       "   0.49148428440093994,\n",
       "   0.4935254454612732,\n",
       "   0.4919748604297638],\n",
       "  'train_loss': [0.12521900236606598,\n",
       "   0.1148223876953125,\n",
       "   0.11404187232255936,\n",
       "   0.11316993087530136,\n",
       "   0.111676886677742,\n",
       "   0.11111896485090256,\n",
       "   0.11055803298950195,\n",
       "   0.11025138944387436,\n",
       "   0.11003432422876358,\n",
       "   0.10987588763237,\n",
       "   0.10976725816726685],\n",
       "  'train_pearson': [0.39793020486831665,\n",
       "   0.4585924446582794,\n",
       "   0.4639986455440521,\n",
       "   0.4704872667789459,\n",
       "   0.48056307435035706,\n",
       "   0.48494067788124084,\n",
       "   0.48844626545906067,\n",
       "   0.49083152413368225,\n",
       "   0.49266934394836426,\n",
       "   0.4932997226715088,\n",
       "   0.4943957030773163]},\n",
       " 'RBP37': {'test_loss': 0.0730680599808693,\n",
       "  'test_pearson': 0.581122100353241,\n",
       "  'val_loss': [0.07643058896064758,\n",
       "   0.07550273835659027,\n",
       "   0.07521849870681763,\n",
       "   0.0746830403804779,\n",
       "   0.07446540892124176,\n",
       "   0.07429100573062897,\n",
       "   0.07450397312641144,\n",
       "   0.07489625364542007,\n",
       "   0.07682958245277405],\n",
       "  'val_pearson': [0.5575284361839294,\n",
       "   0.5623109936714172,\n",
       "   0.5685417056083679,\n",
       "   0.570762038230896,\n",
       "   0.5711449384689331,\n",
       "   0.5719916224479675,\n",
       "   0.5731810927391052,\n",
       "   0.5711878538131714,\n",
       "   0.5737794637680054],\n",
       "  'train_loss': [0.09114422649145126,\n",
       "   0.07573088258504868,\n",
       "   0.07514335215091705,\n",
       "   0.07437466830015182,\n",
       "   0.07409387081861496,\n",
       "   0.07391331344842911,\n",
       "   0.07365616410970688,\n",
       "   0.07374364882707596,\n",
       "   0.07362714409828186],\n",
       "  'train_pearson': [0.5193803906440735,\n",
       "   0.5660521388053894,\n",
       "   0.569868266582489,\n",
       "   0.5750352740287781,\n",
       "   0.5773943662643433,\n",
       "   0.5792138576507568,\n",
       "   0.5799401998519897,\n",
       "   0.5801658630371094,\n",
       "   0.5811349749565125]},\n",
       " 'RBP15': {'test_loss': 0.10245868563652039,\n",
       "  'test_pearson': 0.5302857160568237,\n",
       "  'val_loss': [0.10475771129131317,\n",
       "   0.10271934419870377,\n",
       "   0.10182221233844757,\n",
       "   0.10300590097904205,\n",
       "   0.10173031687736511,\n",
       "   0.1021258756518364,\n",
       "   0.10112731903791428,\n",
       "   0.10177493095397949,\n",
       "   0.10147212445735931,\n",
       "   0.10154592245817184],\n",
       "  'val_pearson': [0.5258631110191345,\n",
       "   0.5336211919784546,\n",
       "   0.5375009179115295,\n",
       "   0.5295844078063965,\n",
       "   0.5404051542282104,\n",
       "   0.5426604747772217,\n",
       "   0.5430045127868652,\n",
       "   0.5392321348190308,\n",
       "   0.5408806204795837,\n",
       "   0.5397589802742004],\n",
       "  'train_loss': [0.11539065837860107,\n",
       "   0.1037551686167717,\n",
       "   0.10295366495847702,\n",
       "   0.10255260020494461,\n",
       "   0.10238075256347656,\n",
       "   0.1022910624742508,\n",
       "   0.10207095742225647,\n",
       "   0.10204034298658371,\n",
       "   0.10184552520513535,\n",
       "   0.10193832218647003],\n",
       "  'train_pearson': [0.5008368492126465,\n",
       "   0.5278228521347046,\n",
       "   0.5323081016540527,\n",
       "   0.534864068031311,\n",
       "   0.5358312726020813,\n",
       "   0.5369288921356201,\n",
       "   0.5377991199493408,\n",
       "   0.5383546352386475,\n",
       "   0.539366602897644,\n",
       "   0.539440929889679]},\n",
       " 'RBP38': {'test_loss': 0.08574000000953674,\n",
       "  'test_pearson': 0.2278282195329666,\n",
       "  'val_loss': [0.08772348612546921,\n",
       "   0.08686058223247528,\n",
       "   0.08650130033493042,\n",
       "   0.08639593422412872,\n",
       "   0.08648975193500519,\n",
       "   0.08612971007823944,\n",
       "   0.08628879487514496,\n",
       "   0.08613788336515427,\n",
       "   0.08607922494411469,\n",
       "   0.08598010241985321,\n",
       "   0.08614177256822586,\n",
       "   0.08603205531835556,\n",
       "   0.08660358190536499],\n",
       "  'val_pearson': [0.18869668245315552,\n",
       "   0.21075113117694855,\n",
       "   0.22087334096431732,\n",
       "   0.22412291169166565,\n",
       "   0.22460846602916718,\n",
       "   0.22864587604999542,\n",
       "   0.23298370838165283,\n",
       "   0.22815674543380737,\n",
       "   0.2329552322626114,\n",
       "   0.23252879083156586,\n",
       "   0.2308291643857956,\n",
       "   0.23139993846416473,\n",
       "   0.22727450728416443],\n",
       "  'train_loss': [0.09303208440542221,\n",
       "   0.08726052939891815,\n",
       "   0.08687794953584671,\n",
       "   0.08651027828454971,\n",
       "   0.0862734317779541,\n",
       "   0.08606696128845215,\n",
       "   0.0859711617231369,\n",
       "   0.08591634035110474,\n",
       "   0.08584316074848175,\n",
       "   0.0858207568526268,\n",
       "   0.08580882847309113,\n",
       "   0.08573165535926819,\n",
       "   0.08579297363758087],\n",
       "  'train_pearson': [0.16806641221046448,\n",
       "   0.2091701328754425,\n",
       "   0.21986576914787292,\n",
       "   0.22563032805919647,\n",
       "   0.23219288885593414,\n",
       "   0.23532448709011078,\n",
       "   0.2372501641511917,\n",
       "   0.23872965574264526,\n",
       "   0.23991942405700684,\n",
       "   0.24048008024692535,\n",
       "   0.24135008454322815,\n",
       "   0.24246414005756378,\n",
       "   0.2415492981672287]},\n",
       " 'RBP14': {'test_loss': 0.09900403767824173,\n",
       "  'test_pearson': 0.4172717034816742,\n",
       "  'val_loss': [0.10148046165704727,\n",
       "   0.10203879326581955,\n",
       "   0.10268085449934006,\n",
       "   0.10070890933275223,\n",
       "   0.1026504635810852,\n",
       "   0.09932872653007507,\n",
       "   0.09950530529022217,\n",
       "   0.102687306702137,\n",
       "   0.09941668063402176],\n",
       "  'val_pearson': [0.4029499888420105,\n",
       "   0.41027557849884033,\n",
       "   0.4109956920146942,\n",
       "   0.4176006019115448,\n",
       "   0.4126526415348053,\n",
       "   0.4194784164428711,\n",
       "   0.41672587394714355,\n",
       "   0.4206131398677826,\n",
       "   0.42002537846565247],\n",
       "  'train_loss': [0.12390726804733276,\n",
       "   0.11685247719287872,\n",
       "   0.11616284400224686,\n",
       "   0.1156625896692276,\n",
       "   0.11535666882991791,\n",
       "   0.11525726318359375,\n",
       "   0.11499974876642227,\n",
       "   0.11491433531045914,\n",
       "   0.11488136649131775],\n",
       "  'train_pearson': [0.3682856857776642,\n",
       "   0.4060734808444977,\n",
       "   0.4117603302001953,\n",
       "   0.41465330123901367,\n",
       "   0.41715988516807556,\n",
       "   0.4185737371444702,\n",
       "   0.420355886220932,\n",
       "   0.42115670442581177,\n",
       "   0.4218839704990387]},\n",
       " 'RBP27': {'test_loss': 0.08871878683567047,\n",
       "  'test_pearson': 0.521532416343689,\n",
       "  'val_loss': [0.09369390457868576,\n",
       "   0.08996749669313431,\n",
       "   0.08879121392965317,\n",
       "   0.08860483020544052,\n",
       "   0.08886200934648514,\n",
       "   0.08835044503211975,\n",
       "   0.08813931047916412,\n",
       "   0.08814514428377151,\n",
       "   0.0904419794678688,\n",
       "   0.08884116262197495],\n",
       "  'val_pearson': [0.5043749213218689,\n",
       "   0.5147736072540283,\n",
       "   0.5252787470817566,\n",
       "   0.5251474976539612,\n",
       "   0.52610844373703,\n",
       "   0.5263177752494812,\n",
       "   0.5281764268875122,\n",
       "   0.5280642509460449,\n",
       "   0.5160831809043884,\n",
       "   0.5262690186500549],\n",
       "  'train_loss': [0.09670442342758179,\n",
       "   0.09139294177293777,\n",
       "   0.09001963585615158,\n",
       "   0.08944563567638397,\n",
       "   0.08912795037031174,\n",
       "   0.08896922320127487,\n",
       "   0.08897265791893005,\n",
       "   0.08881641179323196,\n",
       "   0.08867491781711578,\n",
       "   0.08865402638912201],\n",
       "  'train_pearson': [0.4662357568740845,\n",
       "   0.506123423576355,\n",
       "   0.516139030456543,\n",
       "   0.5210331678390503,\n",
       "   0.522921621799469,\n",
       "   0.5242931246757507,\n",
       "   0.5243676900863647,\n",
       "   0.5253857970237732,\n",
       "   0.5262385010719299,\n",
       "   0.5266677737236023]},\n",
       " 'RBP21': {'test_loss': 0.10948479175567627,\n",
       "  'test_pearson': 0.2602817118167877,\n",
       "  'val_loss': [0.11142916232347488,\n",
       "   0.11167443543672562,\n",
       "   0.11183760315179825,\n",
       "   0.11119619011878967,\n",
       "   0.1107150986790657,\n",
       "   0.11042550206184387,\n",
       "   0.10986048728227615,\n",
       "   0.10952658206224442,\n",
       "   0.10948112607002258,\n",
       "   0.11004099249839783,\n",
       "   0.10967268794775009,\n",
       "   0.10960385948419571],\n",
       "  'val_pearson': [0.23571081459522247,\n",
       "   0.23986518383026123,\n",
       "   0.2397059202194214,\n",
       "   0.2398952841758728,\n",
       "   0.2477485090494156,\n",
       "   0.26018261909484863,\n",
       "   0.2630527913570404,\n",
       "   0.2674318552017212,\n",
       "   0.26826992630958557,\n",
       "   0.26688331365585327,\n",
       "   0.264363557100296,\n",
       "   0.2671101689338684],\n",
       "  'train_loss': [0.11822108924388885,\n",
       "   0.11124449968338013,\n",
       "   0.1110985055565834,\n",
       "   0.11097987741231918,\n",
       "   0.11075469106435776,\n",
       "   0.10992293804883957,\n",
       "   0.10954271256923676,\n",
       "   0.1094074621796608,\n",
       "   0.10934153199195862,\n",
       "   0.10931342840194702,\n",
       "   0.10931513458490372,\n",
       "   0.10927540063858032],\n",
       "  'train_pearson': [0.2237316071987152,\n",
       "   0.24628832936286926,\n",
       "   0.24760696291923523,\n",
       "   0.2485770583152771,\n",
       "   0.25144416093826294,\n",
       "   0.2662550210952759,\n",
       "   0.27154281735420227,\n",
       "   0.2734127342700958,\n",
       "   0.2744970917701721,\n",
       "   0.27484917640686035,\n",
       "   0.27532488107681274,\n",
       "   0.27537527680397034]}}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# create val_loss bar plot, color by train and test\n",
    "train_color = '#7CB342'  # rgb(124, 179, 66)\n",
    "test_color = '#616161'   # rgb(97, 97, 97)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Assuming train_evals and test_evals are dictionaries with 'test_pearson' lists\n",
    "train_pearson = {prot: evals['test_pearson'] for prot, evals in train_evals.items()}\n",
    "test_pearson = {prot: evals['test_pearson'] for prot, evals in test_evals.items()}\n",
    "# plot bar plot for train and test\n",
    "import pandas as pd\n",
    "res_df = pd.DataFrame(test_pearson, index=['pearson_corr']).T\n",
    "res_df['label'] = 'test'\n",
    "res_df2 = pd.DataFrame(train_pearson, index=['pearson_corr']).T\n",
    "res_df2['label'] = 'train'\n",
    "res_df = pd.concat([res_df, res_df2])\n",
    "res_df = res_df.reset_index()\n",
    "res_df = res_df.rename(columns={'index': 'protein'})\n",
    "\n",
    "sns.barplot(data=res_df.dropna(), x='protein', y='pearson_corr', hue='label', palette=[test_color, train_color])\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Pearson correlation')\n",
    "plt.title('Pearson correlation for train and test sets')\n",
    "plt.legend(title='Set')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          set    MSE\n",
      "0  validation  0.102\n",
      "1        test  0.113\n",
      "2       train  0.102\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HTS_to_HTS_result = {'validation': 0.102, 'test': 0.113, 'train': 0.102}\n",
    "\n",
    "# plot bar plot for train and test\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "res_df = pd.DataFrame(HTS_to_HTS_result, index=['MSE']).T\n",
    "res_df\n",
    "res_df = res_df.reset_index()\n",
    "res_df = res_df.rename(columns={'index': 'set'})\n",
    "\n",
    "sns.barplot(data=res_df.dropna(), x='set', y='MSE')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Set')\n",
    "plt.title('HTS to RNAC model MSE')\n",
    "\n",
    "print(res_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pearson'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# bar plot of the pearson correlation coefficient\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_pearson \u001b[38;5;241m=\u001b[39m [evals[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m evals \u001b[38;5;129;01min\u001b[39;00m train_evals\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[1;32m      4\u001b[0m test_pearson \u001b[38;5;241m=\u001b[39m [evals[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m evals \u001b[38;5;129;01min\u001b[39;00m test_evals\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# bar plot of the pearson correlation coefficient\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_pearson \u001b[38;5;241m=\u001b[39m [\u001b[43mevals\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpearson\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m evals \u001b[38;5;129;01min\u001b[39;00m train_evals\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[1;32m      4\u001b[0m test_pearson \u001b[38;5;241m=\u001b[39m [evals[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m evals \u001b[38;5;129;01min\u001b[39;00m test_evals\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pearson'"
     ]
    }
   ],
   "source": [
    "# bar plot of the pearson correlation coefficient\n",
    "train_pearson = [evals['pearson'] for evals in train_evals.values()]\n",
    "\n",
    "test_pearson = [evals['pearson'] for evals in test_evals.values()]\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.bar(range(len(train_pearson)), train_pearson, color=train_color, label='Train proteins (RBP1-38)')\n",
    "plt.bar(range(len(test_pearson)), test_pearson, color=test_color, label='Test proteins (RBP39-76)')\n",
    "plt.title('HTS models Pearson correlation coefficient')\n",
    "plt.xlabel('Protein')\n",
    "plt.ylabel('Pearson correlation coefficient')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepBindEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
